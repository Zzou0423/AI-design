# RAGç³»ç»Ÿè¿ç§»æŒ‡å—

## ğŸ“‹ é¡¹ç›®ä¸­çš„RAGç³»ç»Ÿå®ç°ç»“æ„åˆ†æ

### æ ¸å¿ƒæ¶æ„

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªåŸºäº**LangChain + ChromaDB + DashScope Embeddings**çš„RAGç³»ç»Ÿï¼Œç”¨äºé—®å·ç”Ÿæˆçš„æ£€ç´¢å¢å¼ºç”Ÿæˆã€‚

### ç›®å½•ç»“æ„

```
é¡¹ç›®æ ¹ç›®å½•/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ vector_store.py          # å‘é‡æ•°æ®åº“æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ chains/
â”‚   â”‚   â””â”€â”€ survey_creation_chain.py # RAGæ£€ç´¢é“¾å®ç°
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ survey_service.py        # æœåŠ¡å±‚ï¼ˆä½¿ç”¨RAGï¼‰
â”œâ”€â”€ update_rag_materials.py          # è¯­æ–™åº“æ„å»ºè„šæœ¬
â”œâ”€â”€ rag_materials/                   # è¯­æ–™åº“æ–‡ä»¶å¤¹
â”‚   â”œâ”€â”€ *.pdf                        # PDFè¯­æ–™æ–‡ä»¶
â”‚   â””â”€â”€ .rag_index.json              # è¯­æ–™ç´¢å¼•æ–‡ä»¶
â””â”€â”€ data/
    â””â”€â”€ chroma_db/                   # ChromaDBå‘é‡æ•°æ®åº“æŒä¹…åŒ–ç›®å½•
```

---

## ğŸ”§ æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. å‘é‡å­˜å‚¨æ¨¡å— (`app/core/vector_store.py`)

**åŠŸèƒ½ï¼š**
- PDFæ–‡æ¡£åŠ è½½å’Œæ–‡æœ¬åˆ‡åˆ†
- å‘é‡åŒ–å’ŒæŒä¹…åŒ–å­˜å‚¨
- è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢

**å…³é”®ç±»ï¼š** `SurveyVectorStore`

**æ ¸å¿ƒæ–¹æ³•ï¼š**
- `load_and_split_pdf()`: åŠ è½½PDFå¹¶åˆ‡åˆ†ä¸ºæ–‡æœ¬å—
- `create_vector_store()`: åˆ›å»ºæˆ–åŠ è½½å‘é‡æ•°æ®åº“
- `similarity_search()`: è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
- `add_documents()`: æ·»åŠ æ–‡æ¡£åˆ°å·²æœ‰å‘é‡åº“
- `get_stats()`: è·å–å‘é‡åº“ç»Ÿè®¡ä¿¡æ¯

**é…ç½®å‚æ•°ï¼š**
- `persist_directory`: å‘é‡æ•°æ®åº“æŒä¹…åŒ–ç›®å½• (é»˜è®¤: `./data/chroma_db`)
- `collection_name`: é›†åˆåç§° (é»˜è®¤: `"exemplary_surveys"`)
- `embedding_model`: åµŒå…¥æ¨¡å‹ (é»˜è®¤: `"text-embedding-v3"`)
- `chunk_size`: æ–‡æœ¬å—å¤§å° (é»˜è®¤: 1000å­—ç¬¦)
- `chunk_overlap`: æ–‡æœ¬å—é‡å  (é»˜è®¤: 200å­—ç¬¦)

---

### 2. RAGæ£€ç´¢é“¾ (`app/chains/survey_creation_chain.py`)

**åŠŸèƒ½ï¼š**
- æ•´åˆå‘é‡æ£€ç´¢å’ŒLLMç”Ÿæˆ
- å®ç°æ£€ç´¢å¢å¼ºç”Ÿæˆæµç¨‹

**å…³é”®ç±»ï¼š** `SurveyCreationChain`

**æ ¸å¿ƒæ–¹æ³•ï¼š**
- `generate_survey()`: ç”Ÿæˆé—®å·ï¼ˆä½¿ç”¨RAGï¼‰
- `generate_with_rag()`: ç”Ÿæˆé—®å·å¹¶è¿”å›æ£€ç´¢æ–‡æ¡£
- `_retrieve_context()`: ä»å‘é‡åº“æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡

**å·¥ä½œæµç¨‹ï¼š**
1. æ¥æ”¶ç”¨æˆ·è¾“å…¥
2. ä»å‘é‡åº“æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£ (`retrieval_k` ä¸ª)
3. æ ¼å¼åŒ–æ£€ç´¢ç»“æœä¸ºä¸Šä¸‹æ–‡
4. å°†ä¸Šä¸‹æ–‡å’Œç”¨æˆ·è¾“å…¥åˆå¹¶ä¸ºPrompt
5. è°ƒç”¨LLMç”Ÿæˆç»“æœ
6. è§£æå¹¶è¿”å›JSONæ ¼å¼ç»“æœ

---

### 3. è¯­æ–™åº“æ„å»ºè„šæœ¬ (`update_rag_materials.py`)

**åŠŸèƒ½ï¼š**
- æ‰«æè¯­æ–™æ–‡ä»¶å¤¹ä¸­çš„PDFæ–‡ä»¶
- å¢é‡æ›´æ–°å‘é‡æ•°æ®åº“ï¼ˆåªå¤„ç†æ–°å¢/ä¿®æ”¹çš„æ–‡ä»¶ï¼‰
- ç»´æŠ¤æ–‡ä»¶ç´¢å¼•å’Œå“ˆå¸Œå€¼

**ç‰¹æ€§ï¼š**
- âœ… æ”¯æŒåµŒå¥—æ–‡ä»¶å¤¹
- âœ… MD5å“ˆå¸Œåˆ¤æ–­æ–‡ä»¶å˜æ›´
- âœ… è‡ªåŠ¨åˆ›å»ºç´¢å¼•æ–‡ä»¶ `.rag_index.json`
- âœ… é”™è¯¯å¤„ç†å’Œå¤±è´¥æ–‡ä»¶è®°å½•

---

### 4. æœåŠ¡å±‚é›†æˆ (`app/services/survey_service.py`)

**åŠŸèƒ½ï¼š**
- å°è£…RAGç³»ç»Ÿä¸ºæœåŠ¡æ¥å£
- å¤„ç†éœ€æ±‚æ‰©å†™å’Œé—®å·ç”Ÿæˆ
- ç®¡ç†å‘é‡å­˜å‚¨ç”Ÿå‘½å‘¨æœŸ

**å…³é”®æ–¹æ³•ï¼š**
- `enhance_requirement()`: éœ€æ±‚æ‰©å†™ä¼˜åŒ–
- `create_survey()`: åˆ›å»ºé—®å·ï¼ˆå†…éƒ¨ä½¿ç”¨RAGé“¾ï¼‰
- `create_survey_with_refs()`: åˆ›å»ºé—®å·å¹¶è¿”å›å‚è€ƒæ–‡æ¡£

---

### 5. Web APIé›†æˆ (`run_all.py`)

**APIç«¯ç‚¹ï¼š**
- `POST /api/upload-rag-material`: ä¸Šä¼ PDFè¯­æ–™æ–‡ä»¶
- `GET /api/rag-materials/list`: è·å–å·²ä¸Šä¼ çš„è¯­æ–™åˆ—è¡¨
- `GET /api/rag-materials/status`: è·å–å‘é‡æ•°æ®åº“çŠ¶æ€

**åŠŸèƒ½ï¼š**
- æ–‡ä»¶ä¸Šä¼ å’Œå­˜å‚¨
- è‡ªåŠ¨æ›´æ–°å‘é‡æ•°æ®åº“
- ç´¢å¼•æ–‡ä»¶ç»´æŠ¤

---

## ğŸ“¦ ä¾èµ–é¡¹

### æ ¸å¿ƒä¾èµ–

```python
# å‘é‡æ•°æ®åº“
chromadb>=0.4.0

# LangChainæ¡†æ¶
langchain>=0.1.0
langchain-core>=0.1.0
langchain-community>=0.0.10
langchain-dashscope>=0.0.1

# åµŒå…¥æ¨¡å‹
dashscope>=1.17.0  # é˜¿é‡Œäº‘DashScopeï¼ˆå«text-embedding-v3ï¼‰

# PDFå¤„ç†
pypdf>=3.0.0

# ç¯å¢ƒå˜é‡
python-dotenv>=1.0.0
```

### æ–‡æœ¬åˆ‡åˆ†å™¨

ä½¿ç”¨ `RecursiveCharacterTextSplitter`ï¼Œåˆ‡åˆ†ç­–ç•¥ï¼š
- åˆ†éš”ç¬¦ä¼˜å…ˆçº§: `["\n\n", "\n", "ã€‚", "ï¼›", " ", ""]`
- å—å¤§å°: 1000å­—ç¬¦
- å—é‡å : 200å­—ç¬¦

---

## ğŸš€ è¿ç§»åˆ°å…¶ä»–é¡¹ç›®çš„CursoræŒ‡ä»¤

### æŒ‡ä»¤æ¨¡æ¿

```markdown
è¯·å¸®æˆ‘å°†RAGç³»ç»Ÿè¿ç§»åˆ°å½“å‰é¡¹ç›®ã€‚å…·ä½“è¦æ±‚å¦‚ä¸‹ï¼š

## éœ€è¦è¿ç§»çš„ç»„ä»¶

1. **å‘é‡å­˜å‚¨æ¨¡å—** (`app/core/vector_store.py`)
   - ç±»åï¼š`SurveyVectorStore`
   - åŠŸèƒ½ï¼šPDFåŠ è½½ã€æ–‡æœ¬åˆ‡åˆ†ã€å‘é‡å­˜å‚¨ã€ç›¸ä¼¼åº¦æ£€ç´¢
   - ä¾èµ–ï¼šLangChain + ChromaDB + DashScope Embeddings

2. **RAGæ£€ç´¢é“¾** (`app/chains/survey_creation_chain.py`)
   - ç±»åï¼š`SurveyCreationChain`
   - åŠŸèƒ½ï¼šæ•´åˆå‘é‡æ£€ç´¢å’ŒLLMç”Ÿæˆ
   - éœ€è¦é€‚é…å½“å‰é¡¹ç›®çš„LLMè°ƒç”¨æ–¹å¼

3. **è¯­æ–™åº“æ„å»ºè„šæœ¬** (`update_rag_materials.py`)
   - åŠŸèƒ½ï¼šæ‰«æPDFæ–‡ä»¶ã€å¢é‡æ›´æ–°å‘é‡åº“
   - æ”¯æŒMD5å“ˆå¸Œåˆ¤æ–­æ–‡ä»¶å˜æ›´

## ç›®å½•ç»“æ„è¦æ±‚

è¯·åˆ›å»ºä»¥ä¸‹ç›®å½•ç»“æ„ï¼š
```
é¡¹ç›®æ ¹ç›®å½•/
â”œâ”€â”€ app/ (æˆ–å½“å‰é¡¹ç›®çš„æ¨¡å—ç›®å½•)
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â””â”€â”€ chains/ (æˆ–services/)
â”‚       â””â”€â”€ [è‡ªå®šä¹‰åç§°]_chain.py
â”œâ”€â”€ rag_materials/        # è¯­æ–™åº“æ–‡ä»¶å¤¹
â”‚   â””â”€â”€ .rag_index.json  # ç´¢å¼•æ–‡ä»¶ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”œâ”€â”€ data/
â”‚   â””â”€â”€ chroma_db/       # å‘é‡æ•°æ®åº“ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â””â”€â”€ update_rag_materials.py
```

## é€‚é…è¦æ±‚

1. **åµŒå…¥æ¨¡å‹é€‚é…**
   - å½“å‰ä½¿ç”¨ï¼šDashScope `text-embedding-v3`
   - å¦‚æœéœ€è¦æ›´æ¢ï¼šä¿®æ”¹ `vector_store.py` ä¸­çš„ `embedding_model` å‚æ•°
   - æ”¯æŒå…¶ä»–åµŒå…¥æ¨¡å‹ï¼šOpenAIã€HuggingFaceç­‰

2. **LLMé€‚é…**
   - å½“å‰ä½¿ç”¨ï¼šLangChain DashScope (`ChatDashScope`)
   - éœ€è¦æ ¹æ®é¡¹ç›®ä½¿ç”¨çš„LLMæ¡†æ¶é€‚é… `survey_creation_chain.py`
   - ä¿æŒRAGæ£€ç´¢æµç¨‹ä¸å˜ï¼Œåªéœ€ä¿®æ”¹LLMè°ƒç”¨éƒ¨åˆ†

3. **æ–‡ä»¶è·¯å¾„é€‚é…**
   - å°†æ‰€æœ‰ç¡¬ç¼–ç è·¯å¾„æ”¹ä¸ºå¯é…ç½®å‚æ•°
   - ä½¿ç”¨ `pathlib.Path` å¤„ç†è·¯å¾„

4. **ç¯å¢ƒå˜é‡**
   - `DASHSCOPE_API_KEY`: DashScope APIå¯†é’¥
   - å¦‚éœ€ä½¿ç”¨å…¶ä»–æœåŠ¡ï¼Œæ·»åŠ å¯¹åº”çš„APIå¯†é’¥é…ç½®

## åŠŸèƒ½è¦æ±‚

1. **å‘é‡å­˜å‚¨**
   - âœ… PDFæ–‡æ¡£åŠ è½½å’Œåˆ‡åˆ†
   - âœ… å‘é‡åŒ–å’ŒæŒä¹…åŒ–
   - âœ… è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
   - âœ… æ”¯æŒå¢é‡æ·»åŠ æ–‡æ¡£

2. **è¯­æ–™åº“ç®¡ç†**
   - âœ… è‡ªåŠ¨æ‰«æPDFæ–‡ä»¶
   - âœ… å¢é‡æ›´æ–°ï¼ˆåŸºäºæ–‡ä»¶å“ˆå¸Œï¼‰
   - âœ… ç´¢å¼•æ–‡ä»¶ç»´æŠ¤
   - âœ… é”™è¯¯å¤„ç†å’Œæ—¥å¿—

3. **RAGæ£€ç´¢é“¾**
   - âœ… æŸ¥è¯¢å‘é‡åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£
   - âœ… æ ¼å¼åŒ–æ£€ç´¢ç»“æœä¸ºä¸Šä¸‹æ–‡
   - âœ… åˆå¹¶ä¸Šä¸‹æ–‡å’Œç”¨æˆ·è¾“å…¥
   - âœ… è°ƒç”¨LLMç”Ÿæˆç»“æœ

## æµ‹è¯•è¦æ±‚

è¿ç§»å®Œæˆåï¼Œè¯·æä¾›ï¼š
1. æµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯å‘é‡æ•°æ®åº“æ„å»º
2. æµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯è¯­ä¹‰æ£€ç´¢åŠŸèƒ½
3. æµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯RAGç”Ÿæˆæµç¨‹

## æ–‡æ¡£è¦æ±‚

è¯·ç”Ÿæˆï¼š
1. READMEè¯´æ˜å¦‚ä½•ä½¿ç”¨RAGç³»ç»Ÿ
2. é…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼ˆ.envï¼‰
3. APIä½¿ç”¨ç¤ºä¾‹
```

---

## ğŸ“ è¯¦ç»†å®ç°æ­¥éª¤

### Step 1: åˆ›å»ºå‘é‡å­˜å‚¨æ¨¡å—

**æ–‡ä»¶ï¼š** `app/core/vector_store.py`

**å…³é”®ä»£ç ç»“æ„ï¼š**
```python
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

class SurveyVectorStore:
    def __init__(self, persist_directory, collection_name, embedding_model):
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        self.embeddings = DashScopeEmbeddings(model=embedding_model)
        # åˆå§‹åŒ–æ–‡æœ¬åˆ‡åˆ†å™¨
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", "ã€‚", "ï¼›", " ", ""]
        )
    
    def load_and_split_pdf(self, pdf_path):
        # åŠ è½½PDF
        loader = PyPDFLoader(pdf_path)
        documents = loader.load()
        # åˆ‡åˆ†æ–‡æ¡£
        split_docs = self.text_splitter.split_documents(documents)
        return split_docs
    
    def create_vector_store(self, documents=None):
        # åˆ›å»ºæˆ–åŠ è½½å‘é‡å­˜å‚¨
        if documents:
            self.vector_store = Chroma.from_documents(...)
        else:
            self.vector_store = Chroma(...)
    
    def similarity_search(self, query, k=4):
        # è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
        return self.vector_store.similarity_search(query, k=k)
```

---

### Step 2: åˆ›å»ºRAGæ£€ç´¢é“¾

**æ–‡ä»¶ï¼š** `app/chains/survey_creation_chain.py` (æˆ–è‡ªå®šä¹‰åç§°)

**å…³é”®ä»£ç ç»“æ„ï¼š**
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

class SurveyCreationChain:
    def __init__(self, vector_store, llm_model, retrieval_k=3):
        self.vector_store = vector_store
        self.llm = ChatDashScope(model=llm_model)
        self.retrieval_k = retrieval_k
    
    def _create_chain(self):
        def retrieve_context(user_input):
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            docs = self.vector_store.similarity_search(user_input, k=self.retrieval_k)
            # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
            return format_context(docs)
        
        # åˆ›å»ºRAGé“¾
        chain = (
            RunnablePassthrough.assign(
                retrieved_context=lambda x: retrieve_context(x["user_input"])
            )
            | self.prompt_template
            | self.llm
            | self.output_parser
        )
        return chain
```

---

### Step 3: åˆ›å»ºè¯­æ–™åº“æ„å»ºè„šæœ¬

**æ–‡ä»¶ï¼š** `update_rag_materials.py`

**æ ¸å¿ƒæµç¨‹ï¼š**
1. æ‰«æ `rag_materials/` æ–‡ä»¶å¤¹çš„PDFæ–‡ä»¶
2. è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œ
3. å¯¹æ¯”ç´¢å¼•æ–‡ä»¶ï¼Œæ‰¾å‡ºæ–°å¢/ä¿®æ”¹çš„æ–‡ä»¶
4. åŠ è½½PDFå¹¶åˆ‡åˆ†
5. æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
6. æ›´æ–°ç´¢å¼•æ–‡ä»¶

**å…³é”®å‡½æ•°ï¼š**
```python
def get_file_hash(file_path):
    # è®¡ç®—MD5å“ˆå¸Œ
    
def scan_pdf_files(materials_dir):
    # é€’å½’æ‰«æPDFæ–‡ä»¶
    
def main():
    # ä¸»æµç¨‹ï¼šæ‰«æ â†’ å¯¹æ¯” â†’ å¤„ç† â†’ æ›´æ–°ç´¢å¼•
```

---

### Step 4: é›†æˆåˆ°æœåŠ¡å±‚

**æ–‡ä»¶ï¼š** `app/services/survey_service.py` (æˆ–å¯¹åº”æœåŠ¡æ–‡ä»¶)

**é›†æˆæ–¹å¼ï¼š**
```python
class SurveyService:
    def __init__(self):
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        self.vector_store = SurveyVectorStore(...)
        self.vector_store.create_vector_store()
        
        # åˆå§‹åŒ–RAGé“¾
        self.chain = SurveyCreationChain(
            vector_store=self.vector_store,
            llm_model="qwen-max",
            retrieval_k=3
        )
    
    def create_survey(self, user_input):
        # ä½¿ç”¨RAGé“¾ç”Ÿæˆ
        return self.chain.generate_survey(user_input)
```

---

## ğŸ”„ é€‚é…ä¸åŒLLMæ¡†æ¶

### æ–¹æ¡ˆA: ä½¿ç”¨OpenAI

**ä¿®æ”¹ç‚¹ï¼š**
```python
# vector_store.py
from langchain_openai import OpenAIEmbeddings
self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# survey_creation_chain.py
from langchain_openai import ChatOpenAI
self.llm = ChatOpenAI(model="gpt-4", temperature=0.7)
```

### æ–¹æ¡ˆB: ä½¿ç”¨æœ¬åœ°æ¨¡å‹

**ä¿®æ”¹ç‚¹ï¼š**
```python
# ä½¿ç”¨HuggingFaceåµŒå…¥
from langchain_huggingface import HuggingFaceEmbeddings
self.embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# ä½¿ç”¨Ollamaç­‰æœ¬åœ°LLM
from langchain_ollama import OllamaLLM
self.llm = OllamaLLM(model="llama2")
```

---

## ğŸ“Š é…ç½®å‚æ•°æ€»ç»“

### å‘é‡å­˜å‚¨é…ç½®

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `persist_directory` | `./data/chroma_db` | å‘é‡æ•°æ®åº“å­˜å‚¨ç›®å½• |
| `collection_name` | `"exemplary_surveys"` | ChromaDBé›†åˆåç§° |
| `embedding_model` | `"text-embedding-v3"` | åµŒå…¥æ¨¡å‹åç§° |
| `chunk_size` | `1000` | æ–‡æœ¬å—å¤§å°ï¼ˆå­—ç¬¦ï¼‰ |
| `chunk_overlap` | `200` | æ–‡æœ¬å—é‡å ï¼ˆå­—ç¬¦ï¼‰ |

### RAGæ£€ç´¢é…ç½®

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `retrieval_k` | `3` | æ£€ç´¢è¿”å›çš„æ–‡æ¡£æ•°é‡ |
| `llm_model` | `"qwen-max"` | LLMæ¨¡å‹åç§° |
| `temperature` | `0.7` | LLMæ¸©åº¦å‚æ•° |

---

## âœ… è¿ç§»æ£€æŸ¥æ¸…å•

- [ ] å¤åˆ¶ `vector_store.py` åˆ°ç›®æ ‡é¡¹ç›®
- [ ] å¤åˆ¶ `survey_creation_chain.py` å¹¶é€‚é…LLMè°ƒç”¨
- [ ] å¤åˆ¶ `update_rag_materials.py` å¹¶é€‚é…è·¯å¾„
- [ ] å®‰è£…ä¾èµ–ï¼š`chromadb`, `langchain`, `pypdf` ç­‰
- [ ] é…ç½®ç¯å¢ƒå˜é‡ï¼ˆAPIå¯†é’¥ï¼‰
- [ ] åˆ›å»º `rag_materials/` æ–‡ä»¶å¤¹
- [ ] åˆ›å»º `data/chroma_db/` ç›®å½•ï¼ˆæˆ–é…ç½®æŒä¹…åŒ–è·¯å¾„ï¼‰
- [ ] é€‚é…é¡¹ç›®ä¸­çš„LLMè°ƒç”¨æ–¹å¼
- [ ] æµ‹è¯•å‘é‡æ•°æ®åº“æ„å»º
- [ ] æµ‹è¯•è¯­ä¹‰æ£€ç´¢åŠŸèƒ½
- [ ] æµ‹è¯•RAGç”Ÿæˆæµç¨‹
- [ ] ç¼–å†™ä½¿ç”¨æ–‡æ¡£

---

## ğŸ¯ å¿«é€Ÿè¿ç§»å‘½ä»¤æ¨¡æ¿

```bash
# 1. å®‰è£…ä¾èµ–
pip install chromadb langchain langchain-community langchain-dashscope dashscope pypdf python-dotenv

# 2. åˆ›å»ºç›®å½•ç»“æ„
mkdir -p app/core app/chains rag_materials data/chroma_db

# 3. å¤åˆ¶æ–‡ä»¶
# (é€šè¿‡Cursoræˆ–å…¶ä»–æ–¹å¼å¤åˆ¶æ–‡ä»¶)

# 4. é…ç½®ç¯å¢ƒå˜é‡
echo "DASHSCOPE_API_KEY=your_key_here" > .env

# 5. æ„å»ºå‘é‡æ•°æ®åº“
python update_rag_materials.py

# 6. æµ‹è¯•RAGåŠŸèƒ½
python -m app.services.survey_service
```

---

## ğŸ“š å‚è€ƒæ–‡ä»¶æ¸…å•

è¿ç§»æ—¶éœ€è¦å‚è€ƒçš„æºæ–‡ä»¶ï¼š

1. **æ ¸å¿ƒæ¨¡å—**
   - `app/core/vector_store.py` (278è¡Œ)
   - `app/chains/survey_creation_chain.py` (668è¡Œ)
   - `app/services/survey_service.py` (311è¡Œ)

2. **å·¥å…·è„šæœ¬**
   - `update_rag_materials.py` (240è¡Œ)

3. **é…ç½®æ–‡ä»¶**
   - `requirements.txt` (RAGç›¸å…³ä¾èµ–)
   - `.env.example` (ç¯å¢ƒå˜é‡ç¤ºä¾‹ï¼Œå¦‚æœæœ‰)

4. **æ–‡æ¡£**
   - `rag_materials/README.md` (è¯­æ–™åº“ä½¿ç”¨è¯´æ˜)
   - `docs/RAG_TEST_REPORT.md` (æµ‹è¯•æŠ¥å‘Šï¼Œäº†è§£åŠŸèƒ½)

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```python
from app.core.vector_store import SurveyVectorStore
from app.chains.survey_creation_chain import SurveyCreationChain

# 1. åˆå§‹åŒ–å‘é‡å­˜å‚¨
vector_store = SurveyVectorStore(
    persist_directory="./data/chroma_db",
    collection_name="exemplary_surveys"
)
vector_store.create_vector_store()

# 2. åˆå§‹åŒ–RAGé“¾
chain = SurveyCreationChain(
    vector_store=vector_store,
    llm_model="qwen-max",
    retrieval_k=3
)

# 3. ç”Ÿæˆå†…å®¹
result = chain.generate_survey("ç”¨æˆ·æ»¡æ„åº¦è°ƒæŸ¥")
print(result)
```

### æ·»åŠ æ–°è¯­æ–™

```python
# æ–¹æ³•1: ä½¿ç”¨è„šæœ¬
python update_rag_materials.py

# æ–¹æ³•2: ç¨‹åºåŒ–æ·»åŠ 
documents = vector_store.load_and_split_pdf("new_corpus.pdf")
vector_store.add_documents(documents)
vector_store.persist()
```

---

## ğŸ” è°ƒè¯•å’Œæµ‹è¯•

### æµ‹è¯•å‘é‡å­˜å‚¨

```python
from app.core.vector_store import SurveyVectorStore

vector_store = SurveyVectorStore()
vector_store.create_vector_store()

# æµ‹è¯•æ£€ç´¢
results = vector_store.similarity_search("ç”¨æˆ·æ»¡æ„åº¦", k=3)
for i, doc in enumerate(results, 1):
    print(f"ç»“æœ {i}: {doc.page_content[:200]}...")

# æŸ¥çœ‹ç»Ÿè®¡
stats = vector_store.get_stats()
print(stats)
```

### æµ‹è¯•RAGé“¾

```python
from app.chains.survey_creation_chain import SurveyCreationChain

chain = SurveyCreationChain(retrieval_k=3)
survey, refs = chain.generate_with_rag("äº§å“ä½“éªŒè°ƒç ”")

print(f"æ£€ç´¢åˆ° {len(refs)} ä¸ªå‚è€ƒæ–‡æ¡£")
print(f"ç”Ÿæˆé—®å·åŒ…å« {len(survey['questions'])} ä¸ªé—®é¢˜")
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **APIå¯†é’¥å®‰å…¨**
   - ä¸è¦å°†APIå¯†é’¥æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶
   - ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ç®¡ç†

2. **å‘é‡æ•°æ®åº“è·¯å¾„**
   - ç¡®ä¿æœ‰å†™å…¥æƒé™
   - ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨æŒä¹…åŒ–å­˜å‚¨

3. **æ–‡æ¡£åˆ‡åˆ†å‚æ•°**
   - `chunk_size` å’Œ `chunk_overlap` éœ€è¦æ ¹æ®æ–‡æ¡£ç±»å‹è°ƒæ•´
   - ä¸­æ–‡æ–‡æ¡£å»ºè®®ä½¿ç”¨è¾ƒå°çš„chunk_size

4. **æ£€ç´¢æ•°é‡**
   - `retrieval_k` å½±å“ä¸Šä¸‹æ–‡é•¿åº¦å’Œç”Ÿæˆè´¨é‡
   - å»ºè®®å€¼ï¼š3-5ä¸ªæ–‡æ¡£

5. **é”™è¯¯å¤„ç†**
   - å‘é‡åº“æœªåˆå§‹åŒ–æ—¶çš„é™çº§å¤„ç†
   - æ£€ç´¢å¤±è´¥æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆ

---

## ğŸ“ è¿ç§»æ”¯æŒ

å¦‚æœåœ¨è¿ç§»è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š

1. **ä¾èµ–å®‰è£…**
   ```bash
   pip list | grep -E "chromadb|langchain|dashscope"
   ```

2. **ç¯å¢ƒå˜é‡**
   ```bash
   echo $DASHSCOPE_API_KEY
   ```

3. **å‘é‡æ•°æ®åº“çŠ¶æ€**
   ```python
   vector_store.get_stats()
   ```

4. **æ—¥å¿—è¾“å‡º**
   - æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºçš„è­¦å‘Šå’Œé”™è¯¯ä¿¡æ¯
   - æ£€æŸ¥ `debug_failed_json.txt`ï¼ˆå¦‚æœæœ‰JSONè§£æé”™è¯¯ï¼‰

---

**ç”Ÿæˆæ—¶é—´ï¼š** 2025-01-XX  
**ç‰ˆæœ¬ï¼š** 1.0  
**é€‚ç”¨é¡¹ç›®ï¼š** ai_survey_assistant_2.0




