"""
å®šæ€§åˆ†æå¼•æ“
æ ¸å¿ƒåˆ†ææ¨¡å—ï¼šä»åŸå§‹æ–‡æœ¬æ•°æ®åˆ°ç»“æ„åŒ–æ´å¯Ÿ
"""

import json
import logging
from typing import List, Optional, Dict, Any
from langchain_dashscope import ChatDashScope
from langchain_core.messages import HumanMessage, SystemMessage

from app.models.analysis_models import SurveyAnalysisReport, Theme, Sentiment

logger = logging.getLogger(__name__)


class QualitativeAnalyzer:
    """å®šæ€§åˆ†æå¼•æ“ - æ ¸å¿ƒåˆ†æç±»"""
    
    def __init__(self, llm_model: str = "qwen-flash", temperature: float = 0.7):
        """
        åˆå§‹åŒ–å®šæ€§åˆ†æå™¨
        
        Args:
            llm_model: LLMæ¨¡å‹åç§°ï¼ˆé»˜è®¤ qwen-flashï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼ˆæ§åˆ¶è¾“å‡ºçš„åˆ›é€ æ€§ï¼‰
        """
        self.llm_model = llm_model
        self.temperature = temperature
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        try:
            self.llm_client = ChatDashScope(
                model=llm_model,
                temperature=temperature
            )
            logger.info(f"å®šæ€§åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹: {llm_model}")
        except Exception as e:
            logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm_client = None
            raise
    
    def analyze_open_ended_responses(self, responses: List[str]) -> SurveyAnalysisReport:
        """
        æ ¸å¿ƒåˆ†ææ–¹æ³•ï¼šå¯¹ä¸€æ‰¹å¼€æ”¾é¢˜ç­”æ¡ˆè¿›è¡Œå®šæ€§åˆ†æ
        
        Args:
            responses: å¼€æ”¾é¢˜ç­”æ¡ˆåˆ—è¡¨
            
        Returns:
            SurveyAnalysisReport: ç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Š
        """
        if not self.llm_client:
            raise RuntimeError("LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥APIé…ç½®")
        
        if not responses:
            raise ValueError("å›ç­”åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        
        logger.info(f"å¼€å§‹åˆ†æ {len(responses)} æ¡å¼€æ”¾é¢˜å›ç­”")
        
        # 1. æ•°æ®é¢„å¤„ç†ï¼šæ¸…æ´—ã€å»å™ªã€åˆå¹¶
        cleaned_responses = self._preprocess_responses(responses)
        logger.info(f"é¢„å¤„ç†å®Œæˆï¼Œæœ‰æ•ˆå›ç­”: {len(cleaned_responses)} æ¡")
        
        # 2. è°ƒç”¨LLMè¿›è¡Œä¸»é¢˜ç¼–ç ä¸å†…å®¹åˆ†æ
        analysis_result = self._perform_qualitative_analysis(cleaned_responses)
        
        logger.info(f"åˆ†æå®Œæˆï¼Œè¯†åˆ«å‡º {len(analysis_result.themes)} ä¸ªä¸»é¢˜")
        return analysis_result
    
    def _preprocess_responses(self, responses: List[str]) -> List[str]:
        """
        æ•°æ®é¢„å¤„ç†ï¼šæ¸…æ´—ã€å»å™ªã€åˆå¹¶
        
        Args:
            responses: åŸå§‹å›ç­”åˆ—è¡¨
            
        Returns:
            æ¸…æ´—åçš„å›ç­”åˆ—è¡¨
        """
        cleaned = []
        
        for response in responses:
            if not response:
                continue
            
            # å»é™¤ç©ºç™½å­—ç¬¦
            cleaned_response = response.strip()
            
            # è¿‡æ»¤æ‰å¤ªçŸ­çš„å›ç­”ï¼ˆå°‘äº3ä¸ªå­—ç¬¦ï¼‰
            if len(cleaned_response) < 3:
                continue
            
            # è¿‡æ»¤æ‰é‡å¤çš„å›ç­”ï¼ˆç®€å•çš„å»é‡ï¼‰
            if cleaned_response not in cleaned:
                cleaned.append(cleaned_response)
        
        return cleaned
    
    def _perform_qualitative_analysis(self, responses: List[str]) -> SurveyAnalysisReport:
        """
        æ‰§è¡Œå®šæ€§åˆ†ææ ¸å¿ƒé€»è¾‘
        
        æ ¸å¿ƒæ€è·¯ï¼šè®¾è®¡å¼ºå¤§çš„æç¤ºè¯ï¼Œå¼•å¯¼LLMä¸€æ¬¡æ€§å®Œæˆï¼š
        - ä¸»é¢˜ç¼–ç ï¼šè¯†åˆ«å¹¶å½’çº³æ ¸å¿ƒä¸»é¢˜
        - æƒ…æ„Ÿåˆ¤æ–­å·¥ä½œé‡ï¼šå¯¹æ¯ä¸ªä¸»é¢˜è¿›è¡Œæƒ…æ„Ÿå€¾å‘åˆ¤æ–­
        - å¼•è¿°æå–ï¼šæ‰¾åˆ°ä»£è¡¨æ€§ç”¨æˆ·åŸè¯
        - é¢‘æ¬¡ä¼°ç®—ï¼šä¼°ç®—ä¸»é¢˜æåŠçš„ç›¸å¯¹é¢‘æ¬¡
        
        Args:
            responses: æ¸…æ´—åçš„å›ç­”åˆ—è¡¨
            
        Returns:
            SurveyAnalysisReport: åˆ†æç»“æœ
        """
        # åˆå¹¶æ‰€æœ‰å›ç­”ï¼Œå½¢æˆåˆ†ææ–‡æœ¬
        combined_text = "\n".join([f"- {resp}" for resp in responses])
        total_count = len(responses)
        
        # æ„å»ºåˆ†ææç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€åä¸“ä¸šçš„å®šæ€§åˆ†æä¸“å®¶ï¼Œæ‹¥æœ‰è¶…è¿‡10å¹´çš„é—®å·è®¾è®¡å’Œæ•°æ®åˆ†æç»éªŒã€‚è¯·å¯¹ä»¥ä¸‹ç”¨æˆ·åé¦ˆè¿›è¡Œæ·±å…¥çš„ä¸»é¢˜åˆ†æå’Œå†…å®¹åˆ†æã€‚

ã€åˆ†æè¦æ±‚ã€‘

1. **ä¸»é¢˜ç¼–ç **ï¼šè¯†åˆ«å¹¶å½’çº³å‡ºåé¦ˆä¸­å‡ºç°çš„æ ¸å¿ƒä¸»é¢˜ï¼ˆ3-8ä¸ªï¼‰ï¼Œæ¯ä¸ªä¸»é¢˜ç”¨ç®€çŸ­çš„çŸ­è¯­æ¦‚æ‹¬ï¼ˆå¦‚"å·¥ä½œæ—¶é—´è¿‡é•¿"ã€"å›¢é˜Ÿæ°›å›´è‰¯å¥½"ç­‰ï¼‰ã€‚

2. **æƒ…æ„Ÿåˆ¤æ–­**ï¼šå¯¹æ¯ä¸ªä¸»é¢˜ä¸‹çš„å†…å®¹è¿›è¡Œæƒ…æ„Ÿå€¾å‘åˆ¤æ–­ï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š
   - "positive"ï¼šç§¯ææ­£é¢çš„åé¦ˆ
   - "negative"ï¼šæ¶ˆæè´Ÿé¢çš„åé¦ˆ
   - "neutral"ï¼šä¸­æ€§æˆ–æ··åˆçš„åé¦ˆ

3. **å¼•è¿°æå–**ï¼šä¸ºæ¯ä¸ªä¸»é¢˜æ‰¾åˆ°1-2å¥æœ€å…·ä»£è¡¨æ€§çš„ç”¨æˆ·åŸè¯ä½œä¸ºå¼•è¿°ï¼Œç¡®ä¿å¼•è¿°å‡†ç¡®åæ˜ ä¸»é¢˜å†…å®¹ã€‚

4. **é¢‘æ¬¡ä¼°ç®—**ï¼šåŸºäºè®¨è®ºçš„å¼ºåº¦å’ŒæåŠæ¬¡æ•°ï¼Œä¼°ç®—æ¯ä¸ªä¸»é¢˜è¢«æåŠçš„ç›¸å¯¹é¢‘æ¬¡ï¼ˆæ•´æ•°ï¼Œ1-10ä¹‹é—´ï¼‰ã€‚

5. **ä¸»é¢˜æè¿°**ï¼šä¸ºæ¯ä¸ªä¸»é¢˜æä¾›ç®€çŸ­çš„æè¿°æ€§è¯´æ˜ã€‚

ã€ç”¨æˆ·åé¦ˆæ–‡æœ¬ã€‘ï¼ˆå…± {total_count} æ¡å›ç­”ï¼‰

{combined_text}

ã€è¾“å‡ºè¦æ±‚ã€‘

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™çš„è§£é‡Šæˆ–Markdownä»£ç å—æ ‡è®°ï¼š

{{
    "summary": "æ€»ä½“æ‘˜è¦ï¼ˆ150-200å­—ï¼‰ï¼Œæ¦‚æ‹¬æ‰€æœ‰åé¦ˆçš„æ ¸å¿ƒå†…å®¹å’Œä¸»è¦å‘ç°",
    "themes": [
        {{
            "theme": "ä¸»é¢˜åç§°",
            "sentiment": "positive|negative|neutral",
            "quote": "ä»£è¡¨æ€§ç”¨æˆ·åŸè¯å¼•è¿°",
            "count": 5,
            "description": "ä¸»é¢˜çš„ç®€çŸ­æè¿°"
        }}
    ],
    "recommendation": "å…·ä½“çš„è¡ŒåŠ¨å»ºè®®ï¼ˆ200-300å­—ï¼‰ï¼ŒåŸºäºåˆ†æç»“æœæå‡ºå¯æ“ä½œçš„å»ºè®®"
}}

é‡è¦æç¤ºï¼š
- ç¡®ä¿JSONæ ¼å¼å®Œå…¨æ­£ç¡®
- ä¸»é¢˜æ•°é‡æ§åˆ¶åœ¨3-8ä¸ªä¹‹é—´
- å¼•è¿°å¿…é¡»æ˜¯ç”¨æˆ·åŸè¯ï¼Œä¸è¦ä¿®æ”¹
- æƒ…æ„Ÿåˆ¤æ–­è¦å®¢è§‚å‡†ç¡®
- å»ºè®®è¦å…·ä½“ã€å¯æ“ä½œ
"""
        
        try:
            # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
            messages = [
                SystemMessage(content="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å®šæ€§åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»æ–‡æœ¬ä¸­æå–ä¸»é¢˜ã€åˆ†ææƒ…æ„Ÿå€¾å‘å¹¶æä¾›è¡ŒåŠ¨å»ºè®®ã€‚ä½ å¿…é¡»ä¸¥æ ¼éµå¾ªJSONæ ¼å¼è¾“å‡ºã€‚"),
                HumanMessage(content=prompt)
            ]
            
            response = self.llm_client.invoke(messages)
            content = response.content.strip()
            
            # æ¸…ç†å“åº”å†…å®¹ï¼šç§»é™¤å¯èƒ½çš„Markdownä»£ç å—æ ‡è®°
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                # å°è¯•æå–JSONéƒ¨åˆ†
                parts = content.split("```")
                for part in parts:
                    if "{" in part and "themes" in part:
                        content = part.strip()
                        break
            
            # è§£æJSON
            try:
                result_dict = json.loads(content)
                
                # éªŒè¯å’Œè½¬æ¢æ•°æ®
                themes = []
                for theme_data in result_dict.get("themes", []):
                    try:
                        theme = Theme(
                            theme=theme_data.get("theme", ""),
                            sentiment=Sentiment(theme_data.get("sentiment", "neutral")),
                            quote=theme_data.get("quote", ""),
                            count=theme_data.get("count", 0),
                            description=theme_data.get("description", "")
                        )
                        themes.append(theme)
                    except Exception as e:
                        logger.warning(f"ä¸»é¢˜æ•°æ®è§£æå¤±è´¥: {e}, æ•°æ®: {theme_data}")
                        continue
                
                # æ„å»ºæŠ¥å‘Šå¯¹è±¡
                report = SurveyAnalysisReport(
                    summary=result_dict.get("summary", ""),
                    themes=themes,
                    recommendation=result_dict.get("recommendation", "")
                )
                
                return report
                
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æå¤±è´¥: {e}")
                logger.error(f"å“åº”å†…å®¹: {content[:500]}")
                raise ValueError(f"LLMè¿”å›çš„JSONæ ¼å¼ä¸æ­£ç¡®: {str(e)}")
                
        except Exception as e:
            logger.error(f"å®šæ€§åˆ†ææ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            raise RuntimeError(f"å®šæ€§åˆ†æå¤±è´¥: {str(e)}")
    
    def analyze_by_dimensions(
        self, 
        responses: List[str], 
        dimensions: List[str]
    ) -> Dict[str, SurveyAnalysisReport]:
        """
        æŒ‰é¢„è®¾ç»´åº¦è¿›è¡Œåˆ†æ
        
        ä¾‹å¦‚ï¼šæŒ‰"äº§å“åŠŸèƒ½"ã€"ç”¨æˆ·ä½“éªŒ"ã€"ä»·æ ¼"ç­‰ç»´åº¦åˆ†ç±»åˆ†æ
        
        Args:
            responses: å›ç­”åˆ—è¡¨
            dimensions: é¢„è®¾çš„åˆ†æç»´åº¦åˆ—è¡¨
            
        Returns:
            æ¯ä¸ªç»´åº¦å¯¹åº”çš„åˆ†ææŠ¥å‘Šå­—å…¸
        """
        if not dimensions:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šç»´åº¦ï¼Œç›´æ¥è¿›è¡Œå…¨å±€åˆ†æ
            return {"all": self.analyze_open_ended_responses(responses)}
        
        results = {}
        
        for dimension in dimensions:
            # ä¸ºæ¯ä¸ªç»´åº¦æ„å»ºä¸“é—¨çš„æç¤ºè¯
            dimension_prompt = f"""è¯·ç‰¹åˆ«å…³æ³¨"{dimension}"ç›¸å…³çš„åé¦ˆå†…å®¹ã€‚"""
            
            # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºæ›´å¤æ‚çš„ç»´åº¦è¿‡æ»¤é€»è¾‘
            # ç›®å‰ç®€åŒ–å®ç°ï¼šå…¨å±€åˆ†æä½†åœ¨æç¤ºè¯ä¸­å¼ºè°ƒè¯¥ç»´åº¦
            # TODO: å¯ä»¥å®ç°åŸºäºå…³é”®è¯çš„é¢„è¿‡æ»¤
            
            try:
                report = self.analyze_open_ended_responses(responses)
                results[dimension] = report
            except Exception as e:
                logger.error(f"ç»´åº¦ {dimension} åˆ†æå¤±è´¥: {e}")
                results[dimension] = None
        
        return results
    
    def generate_report(self, report: SurveyAnalysisReport) -> str:
        """
        å°†åˆ†æç»“æœç”Ÿæˆä¸€ä»½æ˜“è¯»çš„MarkdownæŠ¥å‘Š
        
        Args:
            report: åˆ†ææŠ¥å‘Šå¯¹è±¡
            
        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Šå­—ç¬¦ä¸²
        """
        markdown = f"""# é—®å·å®šæ€§åˆ†ææŠ¥å‘Š

## ğŸ“Š æ€»ä½“æ‘˜è¦

{report.summary}

---

## ğŸ¯ æ ¸å¿ƒä¸»é¢˜åˆ†æ

"""
        
        # æŒ‰æƒ…æ„Ÿå€¾å‘åˆ†ç»„å±•ç¤ºä¸»é¢˜
        positive_themes = [t for t in report.themes if t.sentiment == Sentiment.POSITIVE]
        negative_themes = [t for t in report.themes if t.sentiment == Sentiment.NEGATIVE]
        neutral_themes = [t for t in report.themes if t.sentiment == Sentiment.NEUTRAL]
        
        # ç§¯æä¸»é¢˜
        if positive_themes:
            markdown += "### âœ… ç§¯æåé¦ˆä¸»é¢˜\n\n"
            for theme in positive_themes:
                markdown += f"""#### {theme.theme}

- **æƒ…æ„Ÿå€¾å‘**: ç§¯æï¼ˆPositiveï¼‰
- **ä»£è¡¨æ€§å¼•è¿°**: 
  > "{theme.quote}"
- **æåŠé¢‘æ¬¡**: {theme.count}
- **è¯´æ˜**: {theme.description or "æ— "}

"""
        
        # æ¶ˆæä¸»é¢˜
        if negative_themes:
            markdown += "### âš ï¸ éœ€è¦å…³æ³¨çš„ä¸»é¢˜\n\n"
            for theme in negative_themes:
                markdown += f"""#### {theme.theme}

- **æƒ…æ„Ÿå€¾å‘**: æ¶ˆæï¼ˆNegativeï¼‰
- **ä»£è¡¨æ€§å¼•è¿°**: 
  > "{theme.quote}"
- **æåŠé¢‘æ¬¡**: {theme.count}
- **è¯´æ˜**: {theme.description or "æ— "}

"""
        
        # ä¸­æ€§ä¸»é¢˜
        if neutral_themes:
            markdown += "### ğŸ“‹ ä¸­æ€§åé¦ˆä¸»é¢˜\n\n"
            for theme in neutral_themes:
                markdown += f"""#### {theme.theme}

- **æƒ…æ„Ÿå€¾å‘**: ä¸­æ€§ï¼ˆNeutralï¼‰
- **ä»£è¡¨æ€§å¼•è¿°**: 
  > "{theme.quote}"
- **æåŠé¢‘æ¬¡**: {theme.count}
- **è¯´æ˜**: {theme.description or "æ— "}

"""
        
        markdown += f"""---

## ğŸ’¡ è¡ŒåŠ¨å»ºè®®

{report.recommendation}

---

**åˆ†æå®Œæˆæ—¶é—´**: {self._get_current_time()}
"""
        
        return markdown
    
    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

