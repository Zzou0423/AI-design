"""
å…¨é‡åˆ†ææœåŠ¡
ç»¼åˆåˆ†æé—®å·çš„æ‰€æœ‰é¢˜å‹ï¼Œç”Ÿæˆæ·±åº¦è¯Šæ–­æŠ¥å‘Š
"""

import json
import logging
from typing import Dict, Any, List
from collections import Counter
from langchain_dashscope import ChatDashScope
from langchain_core.messages import HumanMessage, SystemMessage

from app.models.analysis_models import (
    QuestionResult, 
    FullAnalysisDataReport, 
    FullAnalysisReport
)
from app.services.qualitative_analyzer import QualitativeAnalyzer
from app.services.visualization_service import VisualizationService

logger = logging.getLogger(__name__)


class FullAnalysisService:
    """å…¨é‡åˆ†ææœåŠ¡ - ä»æè¿°ç»Ÿè®¡åˆ°æ™ºèƒ½è¯Šæ–­"""
    
    def __init__(self, llm_model: str = "qwen-flash", temperature: float = 0.3):
        """
        åˆå§‹åŒ–å…¨é‡åˆ†ææœåŠ¡
        
        Args:
            llm_model: LLMæ¨¡å‹åç§°
            temperature: æ¸©åº¦å‚æ•°ï¼ˆåˆ†ææ—¶ç”¨è¾ƒä½æ¸©åº¦ä¿è¯ä¸¥è°¨æ€§ï¼‰
        """
        self.llm_model = llm_model
        self.temperature = temperature
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ - å¢åŠ max_tokensä»¥æ”¯æŒæ›´é•¿çš„æŠ¥å‘Šè¾“å‡º
        self.llm_client = ChatDashScope(
            model=llm_model,
            temperature=temperature,
            model_kwargs={
                "max_tokens": 8000,  # æ˜¾è‘—å¢åŠ è¾“å‡ºé•¿åº¦é™åˆ¶
                "result_format": "message"
            }
        )
        
        # åˆå§‹åŒ–å®šæ€§åˆ†æå™¨ï¼ˆç”¨äºå¤„ç†å¼€æ”¾é¢˜ï¼‰
        self.qualitative_analyzer = QualitativeAnalyzer(llm_model, temperature=0.7)
        
        # åˆå§‹åŒ–å¯è§†åŒ–æœåŠ¡
        self.viz_service = VisualizationService()
        
        logger.info(f"å…¨é‡åˆ†ææœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹: {llm_model}")
    
    def analyze_full_survey(
        self, 
        survey: Dict[str, Any], 
        responses: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå…¨é‡åˆ†æ
        
        Pipeline:
        1. å‡†å¤‡æ•°æ®æŠ¥å‘Šï¼ˆç»Ÿè®¡æ‰€æœ‰é¢˜å‹ï¼‰
        2. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆä¸ºæ‰€æœ‰é¢˜å‹ï¼‰
        3. ç”Ÿæˆåˆ†ææç¤ºè¯
        4. è°ƒç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æ
        5. è¿”å›MarkdownæŠ¥å‘Š + å¯è§†åŒ–æ•°æ®
        
        Args:
            survey: é—®å·æ•°æ®
            responses: æ‰€æœ‰å›ç­”æ•°æ®
            
        Returns:
            åŒ…å«report_markdownå’Œvisualizationsçš„å­—å…¸
        """
        logger.info(f"å¼€å§‹å…¨é‡åˆ†æï¼Œé—®å·: {survey.get('title')}, å›ç­”æ•°: {len(responses)}")
        
        # 1. å‡†å¤‡æ•°æ®æŠ¥å‘Š
        data_report = self._prepare_data_report(survey, responses)
        
        # 2. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        logger.info("ç”Ÿæˆå…¨é‡åˆ†æå¯è§†åŒ–å›¾è¡¨...")
        visualizations = self._generate_full_visualizations(survey, responses, data_report)
        
        # 3. ç”Ÿæˆåˆ†ææç¤ºè¯
        prompt = self._generate_analysis_prompt(data_report)
        
        # 4. è°ƒç”¨LLM
        logger.info("è°ƒç”¨LLMè¿›è¡Œå…¨é‡åˆ†æ...")
        try:
            messages = [
                SystemMessage(content="""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ•°æ®åˆ†æå¸ˆä¸æˆ˜ç•¥é¡¾é—®ï¼Œæ‹¥æœ‰10å¹´ä»¥ä¸Šçš„è°ƒç ”åˆ†æç»éªŒã€‚
ä½ æ“…é•¿ä»æ•°æ®ä¸­å‘ç°æ·±å±‚æ´å¯Ÿï¼Œå–„äºå…³è”ä¸åŒç»´åº¦çš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿæå‡ºå…·æœ‰æˆ˜ç•¥ä»·å€¼çš„å»ºè®®ã€‚
ä½ çš„åˆ†ææŠ¥å‘Šå¿…é¡»ä½¿ç”¨ä¸¥æ ¼çš„Markdownæ ¼å¼ï¼Œç»“æ„æ¸…æ™°ï¼Œè®ºæ®å……åˆ†ï¼Œå»ºè®®å¯è½åœ°ã€‚

é‡è¦æç¤ºï¼šè¯·åŠ¡å¿…ç”Ÿæˆå®Œæ•´çš„æŠ¥å‘Šï¼Œä¸è¦æˆªæ–­å†…å®¹ã€‚ç¡®ä¿æ‰€æœ‰ç« èŠ‚éƒ½å®Œæ•´è¾“å‡ºã€‚"""),
                HumanMessage(content=prompt)
            ]
            
            response = self.llm_client.invoke(messages)
            markdown_report = response.content.strip()
            
            # æ¸…ç†å¯èƒ½çš„ä»£ç å—æ ‡è®°
            if "```markdown" in markdown_report:
                markdown_report = markdown_report.split("```markdown")[1].split("```")[0].strip()
            elif "```" in markdown_report:
                parts = markdown_report.split("```")
                for part in parts:
                    if "#" in part and len(part) > 100:
                        markdown_report = part.strip()
                        break
            
            # æ£€æŸ¥æŠ¥å‘Šå®Œæ•´æ€§
            is_complete = self._check_report_completeness(markdown_report)
            
            logger.info(f"å…¨é‡åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šé•¿åº¦: {len(markdown_report)} å­—ç¬¦ï¼Œå®Œæ•´æ€§: {'âœ“' if is_complete else 'âœ— å¯èƒ½ä¸å®Œæ•´'}, å¯è§†åŒ–å›¾è¡¨æ•°: {len(visualizations)}")
            
            if not is_complete:
                logger.warning("æŠ¥å‘Šå¯èƒ½ä¸å®Œæ•´ï¼Œå»ºè®®æ£€æŸ¥LLMè¾“å‡º")
                markdown_report += "\n\n---\n\n**âš ï¸ æ³¨æ„**: ç”±äºæŠ¥å‘Šå†…å®¹è¾ƒå¤šï¼Œéƒ¨åˆ†å†…å®¹å¯èƒ½æœªå®Œæ•´æ˜¾ç¤ºã€‚å®Œæ•´åˆ†æç»“æœè¯·ä¸‹è½½PDFæŠ¥å‘ŠæŸ¥çœ‹ã€‚"
            
            return {
                "report_markdown": markdown_report,
                "visualizations": visualizations,
                "is_complete": is_complete
            }
            
        except Exception as e:
            logger.error(f"å…¨é‡åˆ†æå¤±è´¥: {e}", exc_info=True)
            raise RuntimeError(f"å…¨é‡åˆ†æå¤±è´¥: {str(e)}")
    
    def _prepare_data_report(
        self, 
        survey: Dict[str, Any], 
        responses: List[Dict[str, Any]]
    ) -> FullAnalysisDataReport:
        """
        å‡†å¤‡æ•°æ®æŠ¥å‘Šï¼šå°†æ‰€æœ‰é—®é¢˜çš„ç»“æœç»Ÿè®¡å‡ºæ¥
        
        è¿™æ˜¯å…³é”®ä¸€æ­¥ï¼Œè¦æŠŠåŸå§‹æ•°æ®å˜æˆLLMèƒ½ç†è§£çš„"æ•…äº‹æ¢—æ¦‚"
        """
        question_results = []
        
        for question in survey.get("questions", []):
            q_id = str(question.get("id", ""))
            q_type = question.get("type", "")
            q_text = question.get("text", "")
            
            # æ”¶é›†è¯¥é—®é¢˜çš„æ‰€æœ‰ç­”æ¡ˆ
            answers = []
            for response in responses:
                answer_data = response.get("answers", {}).get(q_id)
                if answer_data is not None:
                    answers.append(answer_data)
            
            if not answers:
                continue
            
            # æ ¹æ®é¢˜å‹ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
            result_summary = self._generate_result_summary(question, answers)
            
            question_results.append(QuestionResult(
                question_title=q_text,
                question_type=q_type,
                response_count=len(answers),
                result_summary=result_summary
            ))
        
        return FullAnalysisDataReport(
            survey_title=survey.get("title", ""),
            survey_description=survey.get("description", ""),
            total_respondents=len(responses),
            question_results=question_results
        )
    
    def _generate_result_summary(
        self, 
        question: Dict[str, Any], 
        answers: List[Any]
    ) -> Dict[str, Any]:
        """
        ä¸ºä¸åŒé¢˜å‹ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
        
        å°†æ¯ç‡¥çš„åŸå§‹æ•°æ®å˜æˆLLMèƒ½è½»æ¾ç†è§£çš„"æ•…äº‹æ¢—æ¦‚"
        """
        q_type = question.get("type", "")
        summary = {}
        
        try:
            if q_type == "é‡è¡¨é¢˜":
                # å¤„ç†é‡è¡¨é¢˜ï¼šè®¡ç®—å¹³å‡åˆ†ã€åˆ†å¸ƒ
                numeric_answers = []
                for ans in answers:
                    try:
                        if isinstance(ans, dict):
                            val = float(ans.get("value", 0))
                        else:
                            val = float(ans)
                        numeric_answers.append(val)
                    except (ValueError, TypeError):
                        continue
                
                if numeric_answers:
                    avg_score = sum(numeric_answers) / len(numeric_answers)
                    score_counts = Counter(numeric_answers)
                    
                    # åˆ¤æ–­æ•´ä½“å€¾å‘
                    scale_min = question.get("scale_min", 1)
                    scale_max = question.get("scale_max", 5)
                    mid_point = (scale_min + scale_max) / 2
                    
                    if avg_score >= mid_point + 1:
                        tendency = "æ­£é¢"
                    elif avg_score <= mid_point - 1:
                        tendency = "è´Ÿé¢"
                    else:
                        tendency = "ä¸­æ€§"
                    
                    summary = {
                        "average_score": round(avg_score, 2),
                        "score_distribution": dict(score_counts),
                        "scale_range": f"{scale_min}-{scale_max}",
                        "tendency": tendency,
                        "insight": f"æœ¬é¢˜å¹³å‡å¾—åˆ†ä¸º{avg_score:.2f}ï¼ˆ{scale_min}-{scale_max}åˆ†ï¼‰ï¼Œæ˜¾ç¤ºå‡º{tendency}çš„è¯„ä»·å€¾å‘ã€‚"
                    }
            
            elif q_type == "å•é€‰é¢˜":
                # å¤„ç†å•é€‰é¢˜ï¼šç»Ÿè®¡é€‰é¡¹åˆ†å¸ƒ
                text_answers = []
                for ans in answers:
                    if isinstance(ans, dict):
                        text_answers.append(ans.get("value", ""))
                    else:
                        text_answers.append(str(ans))
                
                option_counts = Counter(text_answers)
                total = len(text_answers)
                
                if option_counts:
                    top_option, top_count = option_counts.most_common(1)[0]
                    top_percentage = (top_count / total * 100) if total > 0 else 0
                    
                    summary = {
                        "option_distribution": dict(option_counts),
                        "top_choice": top_option,
                        "top_percentage": round(top_percentage, 1),
                        "insight": f"å¤§å¤šæ•°å—è®¿è€…ï¼ˆ{top_percentage:.1f}%ï¼‰é€‰æ‹©äº†ã€Œ{top_option}ã€ã€‚"
                    }
            
            elif q_type == "å¤šé€‰é¢˜":
                # å¤„ç†å¤šé€‰é¢˜ï¼šå±•å¼€æ‰€æœ‰é€‰é¡¹è®¡æ•°
                all_choices = []
                for ans in answers:
                    if isinstance(ans, dict):
                        choices = ans.get("value", [])
                    else:
                        choices = ans if isinstance(ans, list) else [ans]
                    all_choices.extend(choices)
                
                option_counts = Counter(all_choices)
                if option_counts:
                    top_3 = option_counts.most_common(3)
                    summary = {
                        "selection_frequency": dict(option_counts),
                        "most_selected": [{"option": opt, "count": cnt} for opt, cnt in top_3],
                        "insight": f"æœ€å¸¸è¢«é€‰æ‹©çš„é€‰é¡¹æ˜¯ã€Œ{top_3[0][0]}ã€ï¼ˆ{top_3[0][1]}æ¬¡ï¼‰ã€‚"
                    }
            
            elif q_type == "å¼€æ”¾å¼é—®é¢˜":
                # å¤„ç†å¼€æ”¾é¢˜ï¼šè°ƒç”¨å®šæ€§åˆ†æ
                text_answers = []
                for ans in answers:
                    if isinstance(ans, dict):
                        text = ans.get("value", "")
                    else:
                        text = str(ans)
                    if text and text.strip():
                        text_answers.append(text.strip())
                
                if text_answers:
                    try:
                        # è°ƒç”¨å®šæ€§åˆ†æå¼•æ“
                        qualitative_report = self.qualitative_analyzer.analyze_open_ended_responses(text_answers)
                        
                        summary = {
                            "main_themes": [t.theme for t in qualitative_report.themes[:5]],
                            "representative_quotes": [t.quote for t in qualitative_report.themes[:3]],
                            "sentiment_summary": self._summarize_sentiment(qualitative_report.themes),
                            "insight": qualitative_report.summary[:200] + "..." if len(qualitative_report.summary) > 200 else qualitative_report.summary
                        }
                    except Exception as e:
                        logger.warning(f"å¼€æ”¾é¢˜åˆ†æå¤±è´¥: {e}")
                        summary = {
                            "insight": f"æ”¶é›†åˆ°{len(text_answers)}æ¡æ–‡æœ¬å›ç­”ã€‚",
                            "sample_quote": text_answers[0] if text_answers else ""
                        }
        
        except Exception as e:
            logger.warning(f"ç”Ÿæˆç»Ÿè®¡æ‘˜è¦å¤±è´¥: {e}")
            summary = {"insight": f"è¯¥é¢˜å…±æ”¶åˆ°{len(answers)}ä¸ªå›ç­”ã€‚"}
        
        return summary
    
    def _summarize_sentiment(self, themes) -> str:
        """æ€»ç»“ä¸»é¢˜çš„æƒ…æ„Ÿå€¾å‘"""
        sentiments = [t.sentiment.value for t in themes]
        sentiment_counts = Counter(sentiments)
        
        if sentiment_counts.get("positive", 0) > sentiment_counts.get("negative", 0):
            return "æ•´ä½“åç§¯æ"
        elif sentiment_counts.get("negative", 0) > sentiment_counts.get("positive", 0):
            return "æ•´ä½“åæ¶ˆæ"
        else:
            return "è¤’è´¬å‚åŠ"
    
    def _generate_analysis_prompt(self, data_report: FullAnalysisDataReport) -> str:
        """
        ç”Ÿæˆå…¨é‡åˆ†ææç¤ºè¯
        
        è¿™æ˜¯æ•´ä¸ªæ¨¡å—çš„å¤§è„‘ï¼Œè´Ÿè´£å°†"åˆ†æç®€æŠ¥"è½¬åŒ–ä¸º"æˆ˜ç•¥æ´å¯Ÿ"
        """
        # 1. æ„å»ºæ•°æ®èƒŒæ™¯éƒ¨åˆ†
        prompt = f"""
ã€è°ƒç ”æ¦‚è¿°ã€‘
è°ƒç ”ä¸»é¢˜ï¼š{data_report.survey_title}
"""
        if data_report.survey_description:
            prompt += f"è°ƒç ”è¯´æ˜ï¼š{data_report.survey_description}\n"
        
        prompt += f"æœ‰æ•ˆæ ·æœ¬é‡ï¼š{data_report.total_respondents} ä»½\n"
        prompt += f"é—®é¢˜æ€»æ•°ï¼š{len(data_report.question_results)} ä¸ª\n"
        
        # 2. è¯¦ç»†åˆ—å‡ºæ¯ä¸ªé—®é¢˜çš„ç»Ÿè®¡ç»“æœ
        prompt += "\nã€è¯¦ç»†æ•°æ®ç»“æœã€‘\n"
        
        for i, q_result in enumerate(data_report.question_results, 1):
            prompt += f"\n{i}. {q_result.question_title}\n"
            prompt += f"   ç±»å‹ï¼š{q_result.question_type}  |  å›ç­”æ•°ï¼š{q_result.response_count}\n"
            
            summary = q_result.result_summary
            
            # æ ¹æ®é¢˜å‹å±•ç¤ºå…³é”®ä¿¡æ¯
            if "insight" in summary:
                prompt += f"   ä¸»è¦å‘ç°ï¼š{summary['insight']}\n"
            
            if q_result.question_type == "é‡è¡¨é¢˜" and "average_score" in summary:
                prompt += f"   å¹³å‡åˆ†ï¼š{summary['average_score']} / {summary.get('scale_range', '')}\n"
                if "score_distribution" in summary:
                    dist = summary['score_distribution']
                    prompt += f"   åˆ†æ•°åˆ†å¸ƒï¼š{dist}\n"
            
            elif q_result.question_type == "å•é€‰é¢˜" and "top_choice" in summary:
                prompt += f"   é¦–é€‰ï¼š{summary['top_choice']} ({summary.get('top_percentage', 0)}%)\n"
            
            elif q_result.question_type == "å¤šé€‰é¢˜" and "most_selected" in summary:
                top_items = summary['most_selected'][:3]
                prompt += f"   é«˜é¢‘é€‰é¡¹ï¼š{', '.join([f'{item['option']}({item['count']}æ¬¡)' for item in top_items])}\n"
            
            elif q_result.question_type == "å¼€æ”¾å¼é—®é¢˜":
                if "main_themes" in summary:
                    prompt += f"   æ ¸å¿ƒä¸»é¢˜ï¼š{', '.join(summary['main_themes'][:3])}\n"
                if "representative_quotes" in summary and summary["representative_quotes"]:
                    prompt += f"   å…¸å‹å¼•è¿°ï¼šã€Œ{summary['representative_quotes'][0]}ã€\n"
                if "sentiment_summary" in summary:
                    prompt += f"   æƒ…æ„Ÿå€¾å‘ï¼š{summary['sentiment_summary']}\n"
        
        # 3. å®šä¹‰åˆ†æä»»åŠ¡å’Œè¦æ±‚
        prompt += """

ã€ä½ çš„åˆ†æä»»åŠ¡ã€‘
åŸºäºä»¥ä¸Šæ•°æ®ï¼Œç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„æˆ˜ç•¥è¯Šæ–­æŠ¥å‘Šã€‚

ã€è¾“å‡ºè¦æ±‚ - æå…¶é‡è¦ã€‘
1. æŠ¥å‘Šå¿…é¡»å®Œæ•´ï¼ŒåŒ…å«æ‰€æœ‰å…­ä¸ªæ ¸å¿ƒç« èŠ‚
2. æ¯ä¸ªç« èŠ‚å†…å®¹è¦ç²¾ç‚¼ï¼Œé¿å…å†—é•¿å™è¿°
3. ä½¿ç”¨ä¸¥æ ¼çš„Markdownæ ¼å¼
4. åŠ¡å¿…è¾“å‡ºåˆ°ç»“è®ºéƒ¨åˆ†ï¼Œä¸å¾—ä¸­é€”æˆªæ–­

ã€è¾“å‡ºæ ¼å¼æ¨¡æ¿ã€‘

```markdown
# å…¨é‡åˆ†æè¯Šæ–­æŠ¥å‘Š

## ä¸€ã€æ ¸å¿ƒæ‘˜è¦
[2-3å¥è¯æ¦‚æ‹¬æœ€å…³é”®å‘ç°]

## äºŒã€å…³é”®å‘ç°
### å‘ç°1ï¼š[æ ‡é¢˜]ï¼ˆé‡è¦æ€§ï¼šé«˜/ä¸­/ä½ï¼‰
- **æ•°æ®**ï¼š[å…·ä½“æ•°å­—]
- **è§£è¯»**ï¼š[1-2å¥è¯´æ˜]

[ç»§ç»­åˆ—å‡º3-5ä¸ªå‘ç°ï¼Œæ¯ä¸ªæ§åˆ¶åœ¨3è¡Œä»¥å†…]

## ä¸‰ã€äº¤å‰æ´å¯Ÿ
### 3.1 å…³è”æ¨¡å¼
[2-3ä¸ªå…³é”®å…³è”ï¼Œæ¯ä¸ª1å¥è¯]

### 3.2 å› æœæ¨æ–­
[2-3ä¸ªå› æœå…³ç³»ï¼Œæ¯ä¸ª1å¥è¯]

### 3.3 ç¾¤ä½“å¯¹æ¯”
[ç”¨è¡¨æ ¼æˆ–ç®€çŸ­æ–‡å­—å¯¹æ¯”2-3ä¸ªç¾¤ä½“]

## å››ã€å…³é”®å°‘æ•°æ´¾
### 4.1 å¼ºçƒˆä¸æ»¡ç¾¤ä½“
[ç‰¹å¾+è¯‰æ±‚ï¼Œ2-3å¥]

### 4.2 é«˜ä»·å€¼ç¾¤ä½“
[ç‰¹å¾+ä»·å€¼ç‚¹ï¼Œ2-3å¥]

## äº”ã€é£é™©ä¸æœºä¼š
### ğŸš¨ ä¸»è¦é£é™©
1. [é£é™©+æ•°æ®]
2. [é£é™©+æ•°æ®]
3. [é£é™©+æ•°æ®]

### âœ¨ æ ¸å¿ƒæœºä¼š
1. [æœºä¼š+æ•°æ®]
2. [æœºä¼š+æ•°æ®]
3. [æœºä¼š+æ•°æ®]

## å…­ã€æˆ˜ç•¥å»ºè®®
### å»ºè®®1ï¼ˆä¼˜å…ˆçº§ï¼šé«˜ï¼‰
**è¡ŒåŠ¨**ï¼š[åšä»€ä¹ˆ]  
**ä¾æ®**ï¼š[ä¸ºä»€ä¹ˆ]  
**æ•ˆæœ**ï¼š[é¢„æœŸç»“æœ]

[ç»§ç»­2-4æ¡å»ºè®®ï¼Œæ¯æ¡æ§åˆ¶åœ¨3è¡Œ]

## ä¸ƒã€ç»“è®º
[1-2å¥æ€»ç»“å…¨æ–‡]
```

ã€å…³é”®çº¦æŸã€‘
- æ¯ä¸ªç« èŠ‚å¿…é¡»å®Œæ•´è¾“å‡º
- ä¼˜å…ˆä¿è¯ç»“æ„å®Œæ•´æ€§ï¼Œè€Œéç»†èŠ‚ä¸°å¯Œåº¦
- å¦‚æœå†…å®¹è¿‡é•¿ï¼Œä¼˜å…ˆç²¾ç®€æè¿°æ–‡å­—ï¼Œä¿ç•™æ•°æ®æ”¯æ’‘
- ç»“è®ºéƒ¨åˆ†å¿…é¡»å‡ºç°ï¼Œæ ‡å¿—æŠ¥å‘Šå®Œæ•´
"""
        
        return prompt
    
    def _check_report_completeness(self, markdown_report: str) -> bool:
        """
        æ£€æŸ¥æŠ¥å‘Šæ˜¯å¦å®Œæ•´
        
        æ£€æŸ¥æ ‡å‡†ï¼š
        1. æ˜¯å¦åŒ…å«"ç»“è®º"ç« èŠ‚
        2. æŠ¥å‘Šé•¿åº¦æ˜¯å¦åˆç†
        3. æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„æˆªæ–­ç‰¹å¾
        
        Args:
            markdown_report: Markdownæ ¼å¼çš„æŠ¥å‘Šå†…å®¹
            
        Returns:
            Trueè¡¨ç¤ºå®Œæ•´ï¼ŒFalseè¡¨ç¤ºå¯èƒ½ä¸å®Œæ•´
        """
        # æ£€æŸ¥1: æ˜¯å¦åŒ…å«ç»“è®ºéƒ¨åˆ†
        if "## ä¸ƒã€ç»“è®º" not in markdown_report and "## ç»“è®º" not in markdown_report:
            return False
        
        # æ£€æŸ¥2: æŠ¥å‘Šé•¿åº¦æ˜¯å¦è¿‡çŸ­ï¼ˆé€šå¸¸å®Œæ•´æŠ¥å‘Šåº”è¯¥æœ‰ä¸€å®šé•¿åº¦ï¼‰
        if len(markdown_report) < 1000:
            return False
        
        # æ£€æŸ¥3: æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„æˆªæ–­ç‰¹å¾ï¼ˆä»¥å¥å­ä¸­é—´ç»“æŸï¼‰
        last_100_chars = markdown_report[-100:].strip()
        # å¦‚æœæœ€åä¸æ˜¯ä»¥æ ‡ç‚¹ç¬¦å·ç»“æŸï¼Œå¯èƒ½è¢«æˆªæ–­
        incomplete_endings = [char for char in last_100_chars[-1:] if char not in 'ã€‚ï¼ï¼Ÿ\n"\'\u3001\uff09\u3011\u300b']
        if incomplete_endings and not any(marker in last_100_chars for marker in ["## ä¸ƒã€ç»“è®º", "## ç»“è®º"]):
            return False
        
        # æ£€æŸ¥4: æ˜¯å¦åŒ…å«å…³é”®ç« èŠ‚
        required_sections = ["## ä¸€ã€æ ¸å¿ƒæ‘˜è¦", "## äºŒã€å…³é”®å‘ç°", "## äº”ã€é£é™©ä¸æœºä¼š", "## å…­ã€æˆ˜ç•¥å»ºè®®"]
        missing_sections = [section for section in required_sections if section not in markdown_report]
        
        if len(missing_sections) > 1:  # å…è®¸å°‘é‡ç« èŠ‚ç¼ºå¤±ï¼Œä½†ä¸èƒ½å¤ªå¤š
            return False
        
        return True
    
    def _generate_full_visualizations(
        self,
        survey: Dict[str, Any],
        responses: List[Dict[str, Any]],
        data_report: FullAnalysisDataReport
    ) -> Dict[str, str]:
        """
        ä¸ºå…¨é‡åˆ†æç”Ÿæˆç»¼åˆå¯è§†åŒ–å›¾è¡¨
        
        åŒ…å«ï¼š
        1. æ‰€æœ‰é‡è¡¨é¢˜çš„åˆ†å¸ƒå›¾
        2. æ‰€æœ‰é€‰æ‹©é¢˜çš„åˆ†å¸ƒå›¾
        3. å¼€æ”¾é¢˜çš„è¯äº‘ã€ä¸»é¢˜åˆ†å¸ƒã€æƒ…æ„Ÿåˆ†å¸ƒ
        
        Args:
            survey: é—®å·æ•°æ®
            responses: å›ç­”æ•°æ®
            data_report: æ•°æ®æŠ¥å‘Š
            
        Returns:
            å¯è§†åŒ–å›¾è¡¨å­—å…¸
        """
        visualizations = {}
        
        try:
            # 1. å¤„ç†æ¯ä¸ªé—®é¢˜ï¼Œç”Ÿæˆå¯¹åº”çš„å¯è§†åŒ–
            for i, q_result in enumerate(data_report.question_results):
                q_type = q_result.question_type
                summary = q_result.result_summary
                
                # é‡è¡¨é¢˜ï¼šç”Ÿæˆåˆ†å¸ƒæŸ±çŠ¶å›¾
                if q_type == "é‡è¡¨é¢˜" and "score_distribution" in summary:
                    chart = self.viz_service.generate_scale_distribution_chart(
                        data=summary["score_distribution"],
                        question_title=q_result.question_title[:30] + "...",  # æˆªçŸ­æ ‡é¢˜
                        scale_range=summary.get("scale_range", "1-5")
                    )
                    if chart:
                        visualizations[f"scale_q{i+1}"] = chart
                        logger.info(f"âœ“ é‡è¡¨é¢˜ {i+1} å¯è§†åŒ–ç”ŸæˆæˆåŠŸ")
                
                # å•é€‰é¢˜ï¼šç”Ÿæˆæ¨ªå‘æŸ±çŠ¶å›¾
                elif q_type == "å•é€‰é¢˜" and "option_distribution" in summary:
                    chart = self.viz_service.generate_choice_distribution_chart(
                        data=summary["option_distribution"],
                        question_title=q_result.question_title[:30] + "...",
                        max_items=10
                    )
                    if chart:
                        visualizations[f"single_choice_q{i+1}"] = chart
                        logger.info(f"âœ“ å•é€‰é¢˜ {i+1} å¯è§†åŒ–ç”ŸæˆæˆåŠŸ")
                
                # å¤šé€‰é¢˜ï¼šç”Ÿæˆæ¨ªå‘æŸ±çŠ¶å›¾
                elif q_type == "å¤šé€‰é¢˜" and "selection_frequency" in summary:
                    chart = self.viz_service.generate_choice_distribution_chart(
                        data=summary["selection_frequency"],
                        question_title=q_result.question_title[:30] + "...",
                        max_items=10
                    )
                    if chart:
                        visualizations[f"multiple_choice_q{i+1}"] = chart
                        logger.info(f"âœ“ å¤šé€‰é¢˜ {i+1} å¯è§†åŒ–ç”ŸæˆæˆåŠŸ")
                
                # å¼€æ”¾é¢˜ï¼šç”Ÿæˆè¯äº‘å’Œä¸»é¢˜åˆ†å¸ƒ
                elif q_type == "å¼€æ”¾å¼é—®é¢˜":
                    # æ”¶é›†è¯¥é¢˜çš„æ‰€æœ‰æ–‡æœ¬ç­”æ¡ˆ
                    question_id = None
                    for q in survey.get("questions", []):
                        if q.get("text") == q_result.question_title or q.get("text", "")[:30] == q_result.question_title[:30]:
                            question_id = str(q.get("id", ""))
                            break
                    
                    if question_id:
                        text_answers = []
                        for response in responses:
                            answer_data = response.get("answers", {}).get(question_id)
                            if answer_data:
                                if isinstance(answer_data, dict):
                                    text = answer_data.get("value", "")
                                else:
                                    text = str(answer_data)
                                if text and text.strip():
                                    text_answers.append(text.strip())
                        
                        if text_answers and len(text_answers) >= 5:
                            # ç”Ÿæˆè¯äº‘
                            wordcloud = self.viz_service.generate_wordcloud(
                                text_answers,
                                title=f"Q{i+1}: {q_result.question_title[:20]}..."
                            )
                            if wordcloud:
                                visualizations[f"wordcloud_q{i+1}"] = wordcloud
                                logger.info(f"âœ“ å¼€æ”¾é¢˜ {i+1} è¯äº‘ç”ŸæˆæˆåŠŸ")
                            
                            # å¦‚æœå·²ç»æœ‰ä¸»é¢˜åˆ†æç»“æœï¼Œç”Ÿæˆä¸»é¢˜åˆ†å¸ƒå›¾
                            if "main_themes" in summary and summary["main_themes"]:
                                # ä¸ºä¸»é¢˜æ·»åŠ è®¡æ•°ä¿¡æ¯ï¼ˆç®€å•ä¼°ç®—ï¼‰
                                themes_with_count = [
                                    {"theme": theme, "count": len(text_answers) // len(summary["main_themes"])}
                                    for theme in summary["main_themes"][:5]
                                ]
                                theme_chart = self.viz_service.generate_theme_distribution_chart(
                                    themes_with_count,
                                    title=f"Q{i+1} ä¸»é¢˜åˆ†å¸ƒ"
                                )
                                if theme_chart:
                                    visualizations[f"themes_q{i+1}"] = theme_chart
                                    logger.info(f"âœ“ å¼€æ”¾é¢˜ {i+1} ä¸»é¢˜åˆ†å¸ƒå›¾ç”ŸæˆæˆåŠŸ")
            
            # 2. ç”Ÿæˆå…¨å±€æ±‡æ€»å›¾è¡¨
            # ç»Ÿè®¡æ‰€æœ‰å¼€æ”¾é¢˜çš„æ–‡æœ¬ç”¨äºç”Ÿæˆæ€»ä½“è¯äº‘
            all_open_texts = []
            for q_result in data_report.question_results:
                if q_result.question_type == "å¼€æ”¾å¼é—®é¢˜":
                    summary = q_result.result_summary
                    if "representative_quotes" in summary:
                        all_open_texts.extend(summary["representative_quotes"])
            
            if all_open_texts:
                overall_wordcloud = self.viz_service.generate_wordcloud(
                    all_open_texts,
                    title=f"{data_report.survey_title} - æ•´ä½“ä¸»é¢˜è¯äº‘"
                )
                if overall_wordcloud:
                    visualizations["overall_wordcloud"] = overall_wordcloud
                    logger.info("âœ“ æ•´ä½“è¯äº‘ç”ŸæˆæˆåŠŸ")
            
            logger.info(f"å…¨é‡åˆ†æå¯è§†åŒ–å®Œæˆï¼Œå…±ç”Ÿæˆ {len(visualizations)} ä¸ªå›¾è¡¨")
            
        except Exception as e:
            logger.warning(f"ç”Ÿæˆå…¨é‡åˆ†æå¯è§†åŒ–æ—¶å‡ºé”™: {e}", exc_info=True)
        
        return visualizations


