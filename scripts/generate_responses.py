"""
é€šç”¨é—®å·ç­”æ¡ˆæ‰¹é‡ç”Ÿæˆè„šæœ¬
è‡ªåŠ¨ä¸ºä»»æ„ä¸»é¢˜çš„é—®å·ç”Ÿæˆç¬¦åˆçœŸå®åœºæ™¯çš„æµ‹è¯•ç­”æ¡ˆ

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨åˆ—å‡ºæ‰€æœ‰å¯ç”¨é—®å·
2. è®©ç”¨æˆ·é€‰æ‹©è¦ç”Ÿæˆç­”æ¡ˆçš„é—®å·
3. è‡ªå®šä¹‰ç”Ÿæˆæ•°é‡
4. æ ¹æ®é—®å·ä¸»é¢˜æ™ºèƒ½ç”Ÿæˆå¤šæ ·åŒ–çš„èº«ä»½è®¾å®š
5. æ‰¹é‡ç”Ÿæˆé«˜è´¨é‡çš„æµ‹è¯•ç­”æ¡ˆ
6. æ”¯æŒå¹¶å‘ç”Ÿæˆï¼Œå¤§å¹…æå‡é€Ÿåº¦

ä½¿ç”¨åœºæ™¯ï¼š
- é—®å·æµ‹è¯•ï¼šåœ¨é—®å·å‘å¸ƒå‰è¿›è¡ŒåŠŸèƒ½æµ‹è¯•
- åˆ†ææ¼”ç¤ºï¼šç”Ÿæˆæ ·æœ¬æ•°æ®ç”¨äºå±•ç¤ºåˆ†æåŠŸèƒ½
- å‹åŠ›æµ‹è¯•ï¼šæµ‹è¯•ç³»ç»Ÿå¯¹å¤§é‡æ•°æ®çš„å¤„ç†èƒ½åŠ›
"""

import json
import os
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Tuple
from dotenv import load_dotenv
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥DashScope
import dashscope
from dashscope import Generation


class ResponseGenerator:
    """é€šç”¨ç­”æ¡ˆç”Ÿæˆå™¨ - æ”¯æŒå¹¶å‘ç”Ÿæˆ"""
    
    def __init__(self, llm_model: str = "qwen-flash", temperature: float = 0.8, max_workers: int = 5):
        """
        åˆå§‹åŒ–ç­”æ¡ˆç”Ÿæˆå™¨
        
        Args:
            llm_model: LLMæ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šqwen-flashï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼ˆé»˜è®¤ï¼š0.8ï¼Œè¶Šé«˜è¶Šå¤šæ ·åŒ–ï¼‰
            max_workers: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤ï¼š5ï¼‰
        """
        self.model = llm_model
        self.temperature = temperature
        self.max_workers = max_workers
    
    def generate_response(
        self, 
        survey_title: str,
        questions: List[Dict], 
        identity: str,
        tendency: str = "neutral"
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆä¸€ä¸ªé—®å·å›ç­”
        
        Args:
            survey_title: é—®å·æ ‡é¢˜
            questions: é—®å·é—®é¢˜åˆ—è¡¨
            identity: èº«ä»½è®¾å®š
            tendency: å›ç­”å€¾å‘ï¼ˆpositive/negative/neutral/mixedï¼‰
            
        Returns:
            ç­”æ¡ˆå­—å…¸
        """
        # å‡†å¤‡é—®é¢˜JSONï¼ˆç²¾ç®€ç‰ˆï¼ŒåªåŒ…å«å¿…è¦ä¿¡æ¯ï¼‰
        simplified_questions = []
        for q in questions:
            simplified_q = {
                "id": q.get("id"),
                "type": q.get("type"),
                "text": q.get("text"),
            }
            if "options" in q:
                simplified_q["options"] = q["options"]
            if q.get("type") == "é‡è¡¨é¢˜":
                simplified_q["scale_range"] = f"{q.get('scale_min', 1)}-{q.get('scale_max', 5)}"
            simplified_questions.append(simplified_q)
        
        questions_json = json.dumps(simplified_questions, ensure_ascii=False, indent=2)
        
        # æ ¹æ®å€¾å‘ç”ŸæˆæŒ‡å¯¼è¯­
        tendency_instructions = {
            "positive": """
ã€å›ç­”å€¾å‘ã€‘ï¼šæ•´ä½“ç§¯ææ­£é¢
- é‡è¡¨é¢˜ï¼šå€¾å‘äºæ‰“4-5åˆ†ï¼ˆé«˜åˆ†ï¼‰
- é€‰æ‹©é¢˜ï¼šé€‰æ‹©æ­£é¢ã€æ»¡æ„ã€è®¤å¯çš„é€‰é¡¹
- å¼€æ”¾é¢˜ï¼šè¡¨è¾¾æ»¡æ„ã€èµèµã€ç§¯æçš„è§‚ç‚¹ï¼Œå¯ä»¥æä¸€äº›å°å»ºè®®ä½†æ•´ä½“è¯­æ°”ç§¯æ""",
            "negative": """
ã€å›ç­”å€¾å‘ã€‘ï¼šæ•´ä½“æ¶ˆæè´Ÿé¢
- é‡è¡¨é¢˜ï¼šå€¾å‘äºæ‰“1-2åˆ†ï¼ˆä½åˆ†ï¼‰
- é€‰æ‹©é¢˜ï¼šé€‰æ‹©è´Ÿé¢ã€ä¸æ»¡ã€æ‰¹è¯„çš„é€‰é¡¹
- å¼€æ”¾é¢˜ï¼šè¡¨è¾¾ä¸æ»¡ã€å¤±æœ›ã€æ‰¹è¯„çš„è§‚ç‚¹ï¼Œå…·ä½“æŒ‡å‡ºé—®é¢˜å’Œä¸è¶³""",
            "neutral": """
ã€å›ç­”å€¾å‘ã€‘ï¼šä¸­ç«‹å®¢è§‚
- é‡è¡¨é¢˜ï¼šå€¾å‘äºæ‰“3åˆ†å·¦å³ï¼ˆä¸­ç­‰ï¼‰
- é€‰æ‹©é¢˜ï¼šé€‰æ‹©ä¸­ç«‹ã€å®¢è§‚çš„é€‰é¡¹
- å¼€æ”¾é¢˜ï¼šå¹³è¡¡åœ°è¡¨è¾¾ä¼˜ç¼ºç‚¹ï¼Œæ—¢æœ‰è‚¯å®šä¹Ÿæœ‰å»ºè®®""",
            "mixed": """
ã€å›ç­”å€¾å‘ã€‘ï¼šè¤’è´¬å‚åŠ
- é‡è¡¨é¢˜ï¼šåˆ†æ•°åˆ†å¸ƒåœ¨2-4åˆ†ä¹‹é—´ï¼Œæœ‰é«˜æœ‰ä½
- é€‰æ‹©é¢˜ï¼šæ—¢é€‰æ­£é¢ä¹Ÿé€‰è´Ÿé¢çš„é€‰é¡¹
- å¼€æ”¾é¢˜ï¼šæ—¢è¡¨è¾¾æ»¡æ„çš„åœ°æ–¹ï¼Œä¹ŸæŒ‡å‡ºä¸æ»¡çš„åœ°æ–¹ï¼ŒçœŸå®åæ˜ å¤æ‚æ„Ÿå—"""
        }
        
        tendency_guide = tendency_instructions.get(tendency, tendency_instructions["neutral"])
        
        # æ„å»ºå¸¦å€¾å‘çš„prompt
        full_prompt = f"""ä½ æ˜¯{identity}ï¼Œæ­£åœ¨å¡«å†™ä¸€ä»½ã€Œ{survey_title}ã€è°ƒæŸ¥é—®å·ã€‚

{tendency_guide}

é—®å·é—®é¢˜ï¼š
{questions_json}

è¯·æ ¹æ®ä½ çš„èº«ä»½èƒŒæ™¯å’ŒæŒ‡å®šçš„å›ç­”å€¾å‘ï¼Œå¡«å†™å®Œæ•´çš„é—®å·ç­”æ¡ˆã€‚ä»¥JSONæ ¼å¼è¿”å›ï¼Œä½¿ç”¨é—®é¢˜çš„idä½œä¸ºkeyã€‚

ç­”é¢˜è§„åˆ™ï¼š
- å•é€‰é¢˜ï¼šè¿”å›å•ä¸ªé€‰é¡¹å­—ç¬¦ä¸²ï¼ˆä»optionsä¸­é€‰æ‹©ä¸€ä¸ªï¼‰
- å¤šé€‰é¢˜ï¼šè¿”å›é€‰é¡¹æ•°ç»„ï¼ˆä»optionsä¸­é€‰æ‹©å¤šä¸ªï¼‰
- é‡è¡¨é¢˜ï¼šè¿”å›æ•°å€¼ï¼ˆåœ¨æŒ‡å®šçš„scale_rangeèŒƒå›´å†…ï¼‰
- å¼€æ”¾å¼é—®é¢˜ï¼šè¿”å›æ–‡æœ¬ï¼ˆ50-200å­—çš„çœŸå®æ„Ÿå—å’Œå…·ä½“æè¿°ï¼‰

æ³¨æ„äº‹é¡¹ï¼š
1. **ä¸¥æ ¼éµå¾ªæŒ‡å®šçš„å›ç­”å€¾å‘**ï¼Œç¡®ä¿ç­”æ¡ˆæ•´ä½“åŸºè°ƒä¸€è‡´
2. ç­”æ¡ˆè¦ç¬¦åˆä½ çš„èº«ä»½è®¾å®šï¼Œé€»è¾‘è¿è´¯
3. å¼€æ”¾é¢˜è¦å†™å¾—å…·ä½“ã€çœŸå®ã€æœ‰ç»†èŠ‚ï¼Œç¬¦åˆæŒ‡å®šå€¾å‘
4. é‡è¡¨æ‰“åˆ†è¦ç¬¦åˆå€¾å‘è¦æ±‚
5. åªè¿”å›JSONæ ¼å¼çš„ç­”æ¡ˆï¼Œä¸è¦ä»»ä½•å…¶ä»–è¯´æ˜æ–‡å­—

è¿”å›æ ¼å¼ç¤ºä¾‹ï¼š
{{
  "1": "é€‰é¡¹A",
  "2": ["é€‰é¡¹1", "é€‰é¡¹2"],
  "3": 4,
  "4": "è¿™æ˜¯ä¸€æ®µè¯¦ç»†çš„æ–‡å­—å›ç­”ï¼ŒåŒ…å«å…·ä½“çš„ä¾‹å­å’Œæ„Ÿå—..."
}}
"""
        
        try:
            # è°ƒç”¨DashScope API
            response = Generation.call(
                model=self.model,
                prompt=full_prompt,
                temperature=self.temperature,
                result_format='message'
            )
            
            if response.status_code == 200:
                # æå–ç­”æ¡ˆå†…å®¹
                content = response.output.choices[0].message.content
                
                # æ¸…ç†å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    parts = content.split("```")
                    if len(parts) > 1:
                        content = parts[1].strip()
                
                # å°è¯•è§£æJSON
                answers = json.loads(content)
                return answers
            else:
                print(f"       [ERROR] APIè°ƒç”¨å¤±è´¥: {response.message}")
                return {}
        except json.JSONDecodeError as e:
            print(f"       [ERROR] JSONè§£æå¤±è´¥: {e}")
            if 'content' in locals():
                print(f"       [DEBUG] å“åº”å†…å®¹: {content[:200]}")
            return {}
        except Exception as e:
            print(f"       [ERROR] è°ƒç”¨å¤±è´¥: {e}")
            return {}
    
    def generate_identities(self, survey_title: str, count: int = 10) -> List[str]:
        """
        æ ¹æ®é—®å·ä¸»é¢˜æ™ºèƒ½ç”Ÿæˆå¤šæ ·åŒ–çš„èº«ä»½è®¾å®š
        
        Args:
            survey_title: é—®å·æ ‡é¢˜
            count: è¦ç”Ÿæˆçš„èº«ä»½æ•°é‡
            
        Returns:
            èº«ä»½è®¾å®šåˆ—è¡¨
        """
        print(f"\n[INFO] æ­£åœ¨ä¸ºã€Œ{survey_title}ã€ç”Ÿæˆèº«ä»½è®¾å®š...")
        
        # ä½¿ç”¨LLMç”Ÿæˆç¬¦åˆä¸»é¢˜çš„èº«ä»½
        prompt = f"""è¯·ä¸ºã€Œ{survey_title}ã€è¿™ä¸ªè°ƒç ”é—®å·ï¼Œç”Ÿæˆ{count}ä¸ªå¤šæ ·åŒ–çš„å—è®¿è€…èº«ä»½è®¾å®šã€‚

è¦æ±‚ï¼š
1. èº«ä»½è¦ç¬¦åˆè¯¥è°ƒç ”çš„ç›®æ ‡å—ä¼—
2. æ¯ä¸ªèº«ä»½è¦æœ‰æ˜ç¡®çš„ç‰¹å¾ï¼ˆå¹´é¾„/èŒä¸š/èƒŒæ™¯/ç»éªŒç­‰ï¼‰
3. èº«ä»½ä¹‹é—´è¦æœ‰å·®å¼‚æ€§ï¼Œè¦†ç›–ä¸åŒç±»å‹çš„å—è®¿è€…
4. æ¯ä¸ªèº«ä»½ç”¨ä¸€å¥è¯æè¿°ï¼ˆ30-60å­—ï¼‰
5. è¿”å›JSONæ•°ç»„æ ¼å¼

ç¤ºä¾‹æ ¼å¼ï¼š
[
  "ä¸€ä½25å²çš„äº’è”ç½‘äº§å“ç»ç†ï¼Œå·¥ä½œ3å¹´ï¼Œç»å¸¸éœ€è¦åŠ ç­ä½†çƒ­çˆ±è‡ªå·±çš„å·¥ä½œ",
  "ä¸€ä½35å²çš„å…¨èŒå¦ˆå¦ˆï¼Œæœ‰ä¸¤ä¸ªå­©å­ï¼Œæ³¨é‡å®¶åº­ç”Ÿæ´»è´¨é‡",
  ...
]

è¯·åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦å…¶ä»–è¯´æ˜ã€‚"""

        try:
            response = Generation.call(
                model=self.model,
                prompt=prompt,
                temperature=0.8,
                result_format='message'
            )
            
            if response.status_code == 200:
                content = response.output.choices[0].message.content
                
                # æ¸…ç†markdownä»£ç å—
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    parts = content.split("```")
                    if len(parts) > 1:
                        content = parts[1].strip()
                
                identities = json.loads(content)
                print(f"[OK] å·²ç”Ÿæˆ {len(identities)} ä¸ªèº«ä»½è®¾å®š")
                return identities
            else:
                print(f"[WARN] LLMç”Ÿæˆèº«ä»½å¤±è´¥ï¼Œä½¿ç”¨é€šç”¨èº«ä»½æ¨¡æ¿")
                return self._get_generic_identities(count)
                
        except Exception as e:
            print(f"[WARN] ç”Ÿæˆèº«ä»½æ—¶å‡ºé”™: {e}ï¼Œä½¿ç”¨é€šç”¨èº«ä»½æ¨¡æ¿")
            return self._get_generic_identities(count)
    
    def _get_generic_identities(self, count: int) -> List[str]:
        """
        è·å–é€šç”¨èº«ä»½æ¨¡æ¿ï¼ˆfallbackï¼‰
        
        Args:
            count: èº«ä»½æ•°é‡
            
        Returns:
            é€šç”¨èº«ä»½åˆ—è¡¨
        """
        generic_identities = [
            "ä¸€ä½25å²çš„å¹´è½»ä¸Šç­æ—ï¼Œå¯¹æ–°é²œäº‹ç‰©å……æ»¡å¥½å¥‡",
            "ä¸€ä½35å²çš„ä¸­å¹´èŒåœºäººå£«ï¼Œæœ‰ä¸°å¯Œçš„ç”Ÿæ´»ç»éªŒ",
            "ä¸€ä½20å²çš„å¤§å­¦ç”Ÿï¼Œæ€ç»´æ´»è·ƒï¼Œå…³æ³¨æ½®æµ",
            "ä¸€ä½45å²çš„èµ„æ·±ä»ä¸šè€…ï¼Œä¸“ä¸šçŸ¥è¯†ä¸°å¯Œ",
            "ä¸€ä½30å²çš„è‡ªç”±èŒä¸šè€…ï¼Œç”Ÿæ´»æ–¹å¼çµæ´»",
            "ä¸€ä½40å²çš„ä¼ä¸šç®¡ç†è€…ï¼Œæ³¨é‡æ•ˆç‡å’Œå“è´¨",
            "ä¸€ä½28å²çš„åˆ›ä¸šè€…ï¼Œå……æ»¡æ¿€æƒ…å’Œæƒ³æ³•",
            "ä¸€ä½50å²çš„è¡Œä¸šä¸“å®¶ï¼Œè§è§£ç‹¬åˆ°",
            "ä¸€ä½22å²çš„åº”å±Šæ¯•ä¸šç”Ÿï¼Œåˆšæ­¥å…¥ç¤¾ä¼š",
            "ä¸€ä½38å²çš„å®¶åº­ä¸»è¦æˆå‘˜ï¼Œæ³¨é‡å®¶åº­å’Œå·¥ä½œå¹³è¡¡",
            "ä¸€ä½32å²çš„æŠ€æœ¯å·¥ä½œè€…ï¼Œå–„äºåˆ†æå’Œæ€è€ƒ",
            "ä¸€ä½26å²çš„è®¾è®¡å¸ˆï¼Œè¿½æ±‚ç¾æ„Ÿå’Œåˆ›æ„",
            "ä¸€ä½42å²çš„æ•™è‚²å·¥ä½œè€…ï¼Œæœ‰è€å¿ƒå’Œè´£ä»»å¿ƒ",
            "ä¸€ä½29å²çš„é”€å”®äººå‘˜ï¼Œå–„äºæ²Ÿé€šå’Œäº¤æµ",
            "ä¸€ä½36å²çš„å…¬åŠ¡å‘˜ï¼Œå·¥ä½œç¨³å®šï¼Œæ³¨é‡è§„èŒƒ"
        ]
        return generic_identities[:count]
    
    def generate_response_batch(
        self,
        survey_title: str,
        questions: List[Dict],
        identities: List[str],
        tendencies: List[str],
        start_index: int = 0
    ) -> List[Tuple[int, Dict[str, Any], str, str]]:
        """
        å¹¶å‘æ‰¹é‡ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            survey_title: é—®å·æ ‡é¢˜
            questions: é—®é¢˜åˆ—è¡¨
            identities: èº«ä»½åˆ—è¡¨
            tendencies: å€¾å‘åˆ—è¡¨ï¼ˆä¸identitieså¯¹åº”ï¼‰
            start_index: èµ·å§‹ç´¢å¼•ï¼ˆç”¨äºæ˜¾ç¤ºè¿›åº¦ï¼‰
            
        Returns:
            [(ç´¢å¼•, ç­”æ¡ˆ, èº«ä»½, å€¾å‘), ...]
        """
        results = []
        
        def generate_single(idx: int, identity: str, tendency: str):
            """ç”Ÿæˆå•ä¸ªç­”æ¡ˆçš„åŒ…è£…å‡½æ•°"""
            try:
                answers = self.generate_response(survey_title, questions, identity, tendency)
                return (idx, answers, identity, tendency, True)
            except Exception as e:
                return (idx, None, identity, tendency, False)
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ç”Ÿæˆ
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_idx = {
                executor.submit(generate_single, i, identities[i], tendencies[i]): i
                for i in range(len(identities))
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_idx):
                result = future.result()
                results.append(result)
        
        # æŒ‰ç´¢å¼•æ’åº
        results.sort(key=lambda x: x[0])
        return results


def list_available_surveys() -> List[Tuple[str, str, Path]]:
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„é—®å·
    
    Returns:
        (é—®å·æ ‡é¢˜, é—®å·ID, æ–‡ä»¶è·¯å¾„) çš„åˆ—è¡¨
    """
    surveys_dir = Path("data/surveys")
    if not surveys_dir.exists():
        return []
    
    surveys = []
    for survey_file in surveys_dir.glob("*.json"):
        try:
            with open(survey_file, 'r', encoding='utf-8') as f:
                survey_data = json.load(f)
            surveys.append((
                survey_data.get("title", "æœªå‘½åé—®å·"),
                survey_data.get("id", ""),
                survey_file
            ))
        except Exception:
            continue
    
    return sorted(surveys, key=lambda x: x[0])


def select_survey() -> Tuple[Dict[str, Any], Path]:
    """
    è®©ç”¨æˆ·é€‰æ‹©è¦ç”Ÿæˆç­”æ¡ˆçš„é—®å·
    
    Returns:
        (é—®å·æ•°æ®, æ–‡ä»¶è·¯å¾„)
    """
    surveys = list_available_surveys()
    
    if not surveys:
        print("\n[ERROR] æœªæ‰¾åˆ°ä»»ä½•é—®å·æ–‡ä»¶")
        print("è¯·å…ˆåœ¨ç³»ç»Ÿä¸­åˆ›å»ºé—®å·ï¼Œé—®å·ä¼šä¿å­˜åœ¨ data/surveys/ ç›®å½•ä¸‹")
        return None, None
    
    print("\nå¯ç”¨çš„é—®å·ï¼š")
    print("-" * 70)
    for idx, (title, survey_id, _) in enumerate(surveys, 1):
        # æ£€æŸ¥ç°æœ‰ç­”æ¡ˆæ•°
        responses_dir = Path("data/responses") / f"{title}_{survey_id}"
        existing_count = len(list(responses_dir.glob("*.json"))) if responses_dir.exists() else 0
        print(f"{idx}. {title}")
        print(f"   ID: {survey_id} | ç°æœ‰ç­”æ¡ˆ: {existing_count} ä»½")
    print("-" * 70)
    
    while True:
        try:
            choice = input("\nè¯·é€‰æ‹©é—®å·ç¼–å· (è¾“å…¥ q é€€å‡º): ").strip()
            if choice.lower() == 'q':
                return None, None
            
            idx = int(choice)
            if 1 <= idx <= len(surveys):
                selected_title, selected_id, selected_path = surveys[idx - 1]
                
                # åŠ è½½é—®å·æ•°æ®
                with open(selected_path, 'r', encoding='utf-8') as f:
                    survey_data = json.load(f)
                
                print(f"\nâœ“ å·²é€‰æ‹©: {selected_title}")
                return survey_data, selected_path
            else:
                print(f"[ERROR] è¯·è¾“å…¥ 1-{len(surveys)} ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("[ERROR] è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except Exception as e:
            print(f"[ERROR] è¯»å–é—®å·å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ¤– AI é—®å·ç­”æ¡ˆæ‰¹é‡ç”Ÿæˆå·¥å…·")
    print("=" * 80)
    print("\nåŠŸèƒ½è¯´æ˜ï¼š")
    print("  - è‡ªåŠ¨ä¸ºä»»æ„ä¸»é¢˜çš„é—®å·ç”Ÿæˆé«˜è´¨é‡æµ‹è¯•ç­”æ¡ˆ")
    print("  - æ ¹æ®é—®å·ä¸»é¢˜æ™ºèƒ½ç”Ÿæˆå¤šæ ·åŒ–çš„å—è®¿è€…èº«ä»½")
    print("  - æ”¯æŒæ‰€æœ‰é¢˜å‹ï¼ˆå•é€‰ã€å¤šé€‰ã€é‡è¡¨ã€å¼€æ”¾é¢˜ï¼‰")
    print("  - ç”Ÿæˆçš„ç­”æ¡ˆé€»è¾‘ä¸€è‡´ã€çœŸå®è‡ªç„¶")
    
    # æ£€æŸ¥API Key
    if not os.getenv("DASHSCOPE_API_KEY"):
        print("\n" + "=" * 80)
        print("[ERROR] DASHSCOPE_API_KEY æœªé…ç½®")
        print("\nè¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š")
        print("1. åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶")
        print("2. æ·»åŠ å†…å®¹ï¼šDASHSCOPE_API_KEY=ä½ çš„APIå¯†é’¥")
        print("3. ä¿å­˜åé‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        print("=" * 80)
        return
    
    # è®©ç”¨æˆ·é€‰æ‹©é—®å·
    survey_data, survey_file = select_survey()
    if not survey_data:
        print("\n[INFO] å·²é€€å‡º")
        return
    
    survey_id = survey_data["id"]
    survey_title = survey_data["title"]
    questions = survey_data["questions"]
    
    print(f"\né—®å·ä¿¡æ¯ï¼š")
    print(f"  - æ ‡é¢˜: {survey_title}")
    print(f"  - é—®é¢˜æ•°é‡: {len(questions)}")
    
    # ç»Ÿè®¡é¢˜å‹
    question_types = {}
    for q in questions:
        q_type = q.get("type", "æœªçŸ¥")
        question_types[q_type] = question_types.get(q_type, 0) + 1
    
    print(f"  - é¢˜å‹åˆ†å¸ƒ: ", end="")
    print(" | ".join([f"{t}Ã—{c}" for t, c in question_types.items()]))
    
    # è¯¢é—®ç”Ÿæˆæ•°é‡
    print("\n" + "-" * 80)
    while True:
        try:
            count_input = input("è¯·è¾“å…¥è¦ç”Ÿæˆçš„ç­”æ¡ˆæ•°é‡ (é»˜è®¤ 30ï¼Œæ¨è 30-100): ").strip()
            if not count_input:
                total_responses = 30
                break
            total_responses = int(count_input)
            if total_responses <= 0:
                print("[ERROR] æ•°é‡å¿…é¡»å¤§äº0")
                continue
            if total_responses > 200:
                confirm = input(f"âš ï¸  ç”Ÿæˆ {total_responses} ä»½ç­”æ¡ˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œç¡®è®¤ç»§ç»­ï¼Ÿ(y/n): ")
                if confirm.lower() != 'y':
                    continue
            break
        except ValueError:
            print("[ERROR] è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    print(f"\nâœ“ å°†ç”Ÿæˆ {total_responses} ä»½ç­”æ¡ˆ")
    
    # é€‰æ‹©å›ç­”å€¾å‘
    print("\n" + "-" * 80)
    print("é€‰æ‹©å›ç­”å€¾å‘ï¼ˆç”¨äºéªŒè¯åˆ†æç»“æœçš„å‡†ç¡®æ€§ï¼‰ï¼š")
    print("  1. ç§¯ææ­£é¢ (positive) - é«˜æ»¡æ„åº¦ã€æ­£é¢è¯„ä»·")
    print("  2. æ¶ˆæè´Ÿé¢ (negative) - ä½æ»¡æ„åº¦ã€è´Ÿé¢è¯„ä»·")  
    print("  3. ä¸­ç«‹å®¢è§‚ (neutral) - ä¸­ç­‰è¯„ä»·ã€å¹³è¡¡åé¦ˆ")
    print("  4. è¤’è´¬å‚åŠ (mixed) - æ··åˆè¯„ä»·ã€æœ‰å¥½æœ‰å")
    print("  5. éšæœºåˆ†å¸ƒ (random) - è‡ªåŠ¨æŒ‰æ¯”ä¾‹åˆ†é…ä¸åŒå€¾å‘")
    print("-" * 80)
    
    tendency_map = {
        "1": ("positive", "ç§¯ææ­£é¢"),
        "2": ("negative", "æ¶ˆæè´Ÿé¢"),
        "3": ("neutral", "ä¸­ç«‹å®¢è§‚"),
        "4": ("mixed", "è¤’è´¬å‚åŠ"),
        "5": ("random", "éšæœºåˆ†å¸ƒ")
    }
    
    while True:
        tendency_choice = input("è¯·é€‰æ‹©å€¾å‘ (1-5, é»˜è®¤5): ").strip()
        if not tendency_choice:
            tendency_choice = "5"
        
        if tendency_choice in tendency_map:
            tendency_mode, tendency_desc = tendency_map[tendency_choice]
            print(f"\nâœ“ å·²é€‰æ‹©: {tendency_desc}")
            break
        else:
            print("[ERROR] è¯·è¾“å…¥ 1-5 ä¹‹é—´çš„æ•°å­—")
    
    # å¦‚æœé€‰æ‹©éšæœºåˆ†å¸ƒï¼Œè®¾ç½®å„å€¾å‘çš„æ¯”ä¾‹
    if tendency_mode == "random":
        print("\n[INFO] éšæœºåˆ†å¸ƒæ¨¡å¼ï¼š")
        print("  - 40% ç§¯ææ­£é¢")
        print("  - 30% ä¸­ç«‹å®¢è§‚")
        print("  - 20% è¤’è´¬å‚åŠ")
        print("  - 10% æ¶ˆæè´Ÿé¢")
    
    # è¯¢é—®å¹¶å‘æ•°
    print("\n" + "-" * 80)
    while True:
        try:
            workers_input = input("å¹¶å‘æ•° (é»˜è®¤ 5ï¼Œæ¨è 3-10ï¼Œè¶Šå¤§è¶Šå¿«ä½†éœ€è¦æ›´å¤šAPIé…é¢): ").strip()
            if not workers_input:
                max_workers = 5
                break
            max_workers = int(workers_input)
            if max_workers <= 0:
                print("[ERROR] å¹¶å‘æ•°å¿…é¡»å¤§äº0")
                continue
            if max_workers > 20:
                print("[WARN] å¹¶å‘æ•°è¿‡å¤§å¯èƒ½å¯¼è‡´APIé™æµ")
                confirm = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(y/n): ")
                if confirm.lower() != 'y':
                    continue
            break
        except ValueError:
            print("[ERROR] è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    
    print(f"âœ“ å¹¶å‘æ•°: {max_workers}")
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    print("\n" + "=" * 80)
    print("[1/4] åˆå§‹åŒ–ç”Ÿæˆå™¨...")
    generator = ResponseGenerator(llm_model="qwen-flash", temperature=0.8, max_workers=max_workers)
    print(f"âœ“ åˆå§‹åŒ–å®Œæˆï¼ˆå¹¶å‘æ•°: {max_workers}ï¼‰")
    
    # ç”Ÿæˆèº«ä»½è®¾å®š
    print("\n[2/4] ç”Ÿæˆå—è®¿è€…èº«ä»½è®¾å®š...")
    identity_count = min(15, total_responses)  # æœ€å¤šç”Ÿæˆ15ä¸ªä¸åŒèº«ä»½
    identities = generator.generate_identities(survey_title, identity_count)
    
    # åˆ›å»ºç­”æ¡ˆä¿å­˜ç›®å½•
    responses_dir = Path("data/responses")
    survey_dir = responses_dir / f"{survey_title}_{survey_id}"
    survey_dir.mkdir(parents=True, exist_ok=True)
    print(f"âœ“ ç­”æ¡ˆå°†ä¿å­˜åˆ°: {survey_dir}")
    
    # ç”Ÿæˆç­”æ¡ˆ
    print(f"\n[3/4] å¼€å§‹ç”Ÿæˆ {total_responses} ä»½ç­”æ¡ˆï¼ˆå¹¶å‘æ¨¡å¼ï¼‰...")
    print("-" * 80)
    
    successful = 0
    failed = 0
    tendency_stats = {"positive": 0, "negative": 0, "neutral": 0, "mixed": 0}
    
    # é¢„è®¡ç®—éšæœºåˆ†å¸ƒçš„å€¾å‘åºåˆ—
    if tendency_mode == "random":
        import random
        tendency_sequence = (
            ["positive"] * int(total_responses * 0.4) +
            ["neutral"] * int(total_responses * 0.3) +
            ["mixed"] * int(total_responses * 0.2) +
            ["negative"] * int(total_responses * 0.1)
        )
        # è¡¥è¶³åˆ°total_responses
        while len(tendency_sequence) < total_responses:
            tendency_sequence.append("neutral")
        random.shuffle(tendency_sequence)
    
    # å‡†å¤‡æ‰€æœ‰ä»»åŠ¡çš„èº«ä»½å’Œå€¾å‘
    all_identities = []
    all_tendencies = []
    for i in range(total_responses):
        identity = identities[i % len(identities)]
        if tendency_mode == "random":
            current_tendency = tendency_sequence[i]
        else:
            current_tendency = tendency_mode
        all_identities.append(identity)
        all_tendencies.append(current_tendency)
    
    # å€¾å‘æ ‡ç­¾
    tendency_labels = {
        "positive": "ğŸ˜Š",
        "negative": "ğŸ˜",
        "neutral": "ğŸ˜",
        "mixed": "ğŸ¤”"
    }
    
    # åˆ†æ‰¹å¹¶å‘ç”Ÿæˆï¼ˆæ¯æ‰¹max_workersä¸ªï¼‰
    batch_size = max_workers * 2  # æ¯æ‰¹å¤„ç†å¹¶å‘æ•°çš„2å€
    total_batches = (total_responses + batch_size - 1) // batch_size
    
    print(f"ğŸ’¡ ä½¿ç”¨ {max_workers} ä¸ªå¹¶å‘çº¿ç¨‹ï¼Œåˆ† {total_batches} æ‰¹å¤„ç†")
    print(f"â±ï¸  é¢„è®¡è€—æ—¶: {total_responses / max_workers / 2:.1f}-{total_responses / max_workers:.1f} åˆ†é’Ÿ")
    print()
    
    start_time = time.time()
    
    try:
        for batch_idx in range(total_batches):
            batch_start = batch_idx * batch_size
            batch_end = min((batch_idx + 1) * batch_size, total_responses)
            batch_count = batch_end - batch_start
            
            print(f"ğŸ“¦ æ‰¹æ¬¡ {batch_idx + 1}/{total_batches}: ç”Ÿæˆ {batch_start + 1}-{batch_end} ä»½...")
            
            # å‡†å¤‡å½“å‰æ‰¹æ¬¡çš„æ•°æ®
            batch_identities = all_identities[batch_start:batch_end]
            batch_tendencies = all_tendencies[batch_start:batch_end]
            
            # å¹¶å‘ç”Ÿæˆå½“å‰æ‰¹æ¬¡
            batch_results = generator.generate_response_batch(
                survey_title,
                questions,
                batch_identities,
                batch_tendencies,
                batch_start
            )
            
            # å¤„ç†ç»“æœå¹¶ä¿å­˜
            for idx, answers, identity, current_tendency, success in batch_results:
                global_idx = batch_start + idx
                
                if not success or not answers:
                    failed += 1
                    print(f"  [{global_idx + 1}/{total_responses}] {tendency_labels.get(current_tendency, '')} âœ— å¤±è´¥")
                    continue
                
                tendency_stats[current_tendency] += 1
                
                # ç”Ÿæˆç”¨æˆ·ID
                user_id = f"user_{uuid.uuid4().hex[:10]}"
                
                # æ„å»ºç­”æ¡ˆæ•°æ®
                response_data = {
                    "survey_id": survey_id,
                    "survey_info": {
                        "title": survey_title,
                        "description": survey_data.get("description", "")
                    },
                    "submitted_at": datetime.now().isoformat(),
                    "answers": answers,
                    "user_identity": identity,
                    "response_tendency": current_tendency
                }
                
                # ä¿å­˜ç­”æ¡ˆ
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                filename = f"{timestamp}_{user_id}_{survey_id}.json"
                filepath = survey_dir / filename
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(response_data, f, ensure_ascii=False, indent=2)
                
                successful += 1
                print(f"  [{global_idx + 1}/{total_responses}] {tendency_labels.get(current_tendency, '')} âœ“")
            
            # æ˜¾ç¤ºæ‰¹æ¬¡ç»Ÿè®¡
            elapsed = time.time() - start_time
            avg_time = elapsed / (batch_end) if batch_end > 0 else 0
            remaining = (total_responses - batch_end) * avg_time
            print(f"  â±ï¸  å·²ç”¨æ—¶: {elapsed:.1f}ç§’ | é¢„è®¡å‰©ä½™: {remaining:.1f}ç§’")
            print()
    
    except KeyboardInterrupt:
        print("\n\n[INFO] ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜å·²ç”Ÿæˆçš„ç­”æ¡ˆ...")
    except Exception as e:
        print(f"\n[ERROR] æ‰¹é‡ç”Ÿæˆå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    # ç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 80)
    print("[4/4] ç”Ÿæˆå®Œæˆ!")
    print("-" * 80)
    print(f"âœ“ æˆåŠŸ: {successful} ä»½")
    if failed > 0:
        print(f"âœ— å¤±è´¥: {failed} ä»½")
    print(f"ğŸ“ ä¿å­˜ä½ç½®: {survey_dir}")
    print("=" * 80)
    
    # æ˜¾ç¤ºå€¾å‘åˆ†å¸ƒç»Ÿè®¡
    print("\nğŸ“Š ç­”æ¡ˆå€¾å‘åˆ†å¸ƒç»Ÿè®¡ï¼š")
    print("-" * 80)
    total_actual = sum(tendency_stats.values())
    if total_actual > 0:
        print(f"ğŸ˜Š ç§¯ææ­£é¢: {tendency_stats['positive']} ä»½ ({tendency_stats['positive']/total_actual*100:.1f}%)")
        print(f"ğŸ˜ æ¶ˆæè´Ÿé¢: {tendency_stats['negative']} ä»½ ({tendency_stats['negative']/total_actual*100:.1f}%)")
        print(f"ğŸ˜ ä¸­ç«‹å®¢è§‚: {tendency_stats['neutral']} ä»½ ({tendency_stats['neutral']/total_actual*100:.1f}%)")
        print(f"ğŸ¤” è¤’è´¬å‚åŠ: {tendency_stats['mixed']} ä»½ ({tendency_stats['mixed']/total_actual*100:.1f}%)")
        print("-" * 80)
        
        # é¢„æœŸåˆ†æç»“æœæç¤º
        print("\nğŸ” é¢„æœŸåˆ†æç»“æœï¼š")
        if tendency_mode == "positive":
            print("  âœ“ åˆ†ææŠ¥å‘Šåº”æ˜¾ç¤ºï¼šé«˜æ»¡æ„åº¦ã€ç§¯æä¸»é¢˜å ä¸»å¯¼ã€æƒ…æ„Ÿå€¾å‘åæ­£é¢")
        elif tendency_mode == "negative":
            print("  âœ“ åˆ†ææŠ¥å‘Šåº”æ˜¾ç¤ºï¼šä½æ»¡æ„åº¦ã€è´Ÿé¢ä¸»é¢˜å ä¸»å¯¼ã€æƒ…æ„Ÿå€¾å‘åè´Ÿé¢")
        elif tendency_mode == "neutral":
            print("  âœ“ åˆ†ææŠ¥å‘Šåº”æ˜¾ç¤ºï¼šä¸­ç­‰è¯„ä»·ã€å®¢è§‚ä¸»é¢˜ã€æƒ…æ„Ÿå€¾å‘ä¸­æ€§")
        elif tendency_mode == "mixed":
            print("  âœ“ åˆ†ææŠ¥å‘Šåº”æ˜¾ç¤ºï¼šè¤’è´¬å‚åŠã€æ­£è´Ÿä¸»é¢˜æ··åˆã€æƒ…æ„Ÿå€¾å‘æ··åˆ")
        elif tendency_mode == "random":
            print("  âœ“ åˆ†ææŠ¥å‘Šåº”æ˜¾ç¤ºï¼šå¤šæ ·åŒ–è¯„ä»·ã€æ­£é¢ä¸»é¢˜ä¸ºä¸»ã€æƒ…æ„Ÿåˆ†å¸ƒè¾ƒå‡è¡¡")
        
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®ï¼š")
        print("  1. åœ¨ç³»ç»Ÿä¸­å¯¹è¯¥é—®å·è¿›è¡Œåˆ†æ")
        print("  2. å¯¹æ¯”åˆ†æç»“æœä¸é¢„æœŸå€¾å‘")
        print("  3. éªŒè¯åˆ†æå¼•æ“çš„å‡†ç¡®æ€§")
        print("  4. æ£€æŸ¥å¯è§†åŒ–å›¾è¡¨æ˜¯å¦ç¬¦åˆæ•°æ®åˆ†å¸ƒ")
    
    # ç»Ÿè®¡æ€»å›ç­”æ•°
    existing_responses = len(list(survey_dir.glob("*.json")))
    print(f"\nğŸ“Š è¯¥é—®å·ç°å…±æœ‰ {existing_responses} ä»½ç­”æ¡ˆ")
    print("=" * 80)


if __name__ == "__main__":
    main()

